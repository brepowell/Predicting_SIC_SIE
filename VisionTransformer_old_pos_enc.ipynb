{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1a28e7d-dc79-40f6-a74a-8a679428fce5",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7b09f00-1689-4691-8150-4c794246e98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Version: 3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:45:41) [GCC 13.3.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print('System Version:', sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6360503b-6b8b-469e-87f0-2728b3f06a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sys.executable) # for troubleshooting kernel issues\n",
    "#print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95c8c6ca-37fa-4862-ae15-9533e9be2a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e01aaf1-72c2-4519-8686-940b4479f6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version 2.2.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print('Numpy version', np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9cb8e5c-b522-4079-a77a-781ef3898b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print('Pandas version', pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79e968c7-1f0b-4bec-ab94-febc3c468ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xarray version 2025.6.1\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "print('Xarray version', xr.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c880f9f7-f618-49d9-8f90-b26a8ce0105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6f4c9f4-1822-477f-be68-9355e0ca1fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplotlib version 3.10.3\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "print('Matplotlib version', matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23254110-90d5-4ea1-9e3d-dfc0c8f4ce4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 2.5.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "print('PyTorch version', torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3720a6-37d6-40aa-acb0-5aa1cd3cee40",
   "metadata": {},
   "source": [
    "# Hardware Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4d15e35-d5b4-41e2-956d-95b6504edcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    raise ValueError(\"There is a problem with Torch not recognizing the GPUs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40ead02e-ae14-41bb-a7fd-6242e11003f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count()) # check the number of available CUDA devices\n",
    "# will print 1 on login node; 4 on GPU exclusive node; 1 on shared GPU node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38d6e907-60d0-4502-9123-e183f25c4b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(torch.cuda.get_device_properties(0)) #provides information about a specific GPU\n",
    "\n",
    "#total_memory=40326MB, multi_processor_count=108, L2_cache_size=40MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fc99a47-c7fa-477c-a697-00e3f34ece6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor Name: x86_64\n",
      "Physical Cores: 64\n",
      "Logical Cores: 128\n",
      "Current CPU Frequency: 2487.32 MHz\n",
      "Min CPU Frequency: 1500.00 MHz\n",
      "Max CPU Frequency: 2450.00 MHz\n",
      "Total CPU Usage: 0.3%\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import platform\n",
    "\n",
    "# Get general CPU information\n",
    "processor_name = platform.processor()\n",
    "print(f\"Processor Name: {processor_name}\")\n",
    "\n",
    "# Get core counts\n",
    "physical_cores = psutil.cpu_count(logical=False)\n",
    "logical_cores = psutil.cpu_count(logical=True)\n",
    "print(f\"Physical Cores: {physical_cores}\")\n",
    "print(f\"Logical Cores: {logical_cores}\")\n",
    "\n",
    "# Get CPU frequency\n",
    "cpu_frequency = psutil.cpu_freq()\n",
    "if cpu_frequency:\n",
    "    print(f\"Current CPU Frequency: {cpu_frequency.current:.2f} MHz\")\n",
    "    print(f\"Min CPU Frequency: {cpu_frequency.min:.2f} MHz\")\n",
    "    print(f\"Max CPU Frequency: {cpu_frequency.max:.2f} MHz\")\n",
    "\n",
    "# Get CPU utilization (percentage)\n",
    "# The interval argument specifies the time period over which to measure CPU usage.\n",
    "# Setting percpu=True gives individual core utilization.\n",
    "cpu_percent_total = psutil.cpu_percent(interval=1)\n",
    "print(f\"Total CPU Usage: {cpu_percent_total}%\")\n",
    "\n",
    "# cpu_percent_per_core = psutil.cpu_percent(interval=1, percpu=True)\n",
    "# print(\"CPU Usage per Core:\")\n",
    "# for i, percent in enumerate(cpu_percent_per_core):\n",
    "#     print(f\"  Core {i+1}: {percent}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fd50d6-18a5-4f14-94c6-56d69814e0e6",
   "metadata": {},
   "source": [
    "# Example of one netCDF file with xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db4edde5-7f16-4f36-a069-b97fb9844378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = xr.open_dataset(\"train/v3.LR.DTESTM.pm-cpu-10yr.mpassi.hist.am.timeSeriesStatsDaily.0010-01-01.nc\")\n",
    "\n",
    "from perlmutterpath import * # has the path to the data on Perlmutter\n",
    "ds = xr.open_dataset(full_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2955c68e-3428-4d41-b556-16226329b67c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data variables:\n",
       "    timeDaily_counter             (Time) int32 124B ...\n",
       "    xtime_startDaily              (Time) |S64 2kB ...\n",
       "    xtime_endDaily                (Time) |S64 2kB ...\n",
       "    timeDaily_avg_iceAreaCell     (Time, nCells) float32 58MB ...\n",
       "    timeDaily_avg_iceVolumeCell   (Time, nCells) float32 58MB ...\n",
       "    timeDaily_avg_snowVolumeCell  (Time, nCells) float32 58MB ...\n",
       "    timeDaily_avg_uVelocityGeo    (Time, nVertices) float32 117MB ...\n",
       "    timeDaily_avg_vVelocityGeo    (Time, nVertices) float32 117MB ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.data_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67e633a4-1006-47dd-a2bf-52ee17e6c7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_counter = ds[\"timeDaily_counter\"]\n",
    "day_counter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "552710e3-15d2-4a86-b14f-3bc036d7e3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'xtime_startDaily' (Time: 31)> Size: 2kB\n",
      "[31 values with dtype=|S64]\n",
      "Dimensions without coordinates: Time\n"
     ]
    }
   ],
   "source": [
    "print(ds[\"xtime_startDaily\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90545b27-4a01-4421-91b1-aed28af2282a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'2024-12-01_00:00:00' b'2024-12-02_00:00:00' b'2024-12-03_00:00:00'\n",
      " b'2024-12-04_00:00:00' b'2024-12-05_00:00:00' b'2024-12-06_00:00:00'\n",
      " b'2024-12-07_00:00:00' b'2024-12-08_00:00:00' b'2024-12-09_00:00:00'\n",
      " b'2024-12-10_00:00:00' b'2024-12-11_00:00:00' b'2024-12-12_00:00:00'\n",
      " b'2024-12-13_00:00:00' b'2024-12-14_00:00:00' b'2024-12-15_00:00:00'\n",
      " b'2024-12-16_00:00:00' b'2024-12-17_00:00:00' b'2024-12-18_00:00:00'\n",
      " b'2024-12-19_00:00:00' b'2024-12-20_00:00:00' b'2024-12-21_00:00:00'\n",
      " b'2024-12-22_00:00:00' b'2024-12-23_00:00:00' b'2024-12-24_00:00:00'\n",
      " b'2024-12-25_00:00:00' b'2024-12-26_00:00:00' b'2024-12-27_00:00:00'\n",
      " b'2024-12-28_00:00:00' b'2024-12-29_00:00:00' b'2024-12-30_00:00:00'\n",
      " b'2024-12-31_00:00:00']\n"
     ]
    }
   ],
   "source": [
    "print(ds[\"xtime_startDaily\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d832e806-4dbd-4139-b08a-546abcac3ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 465044)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ice_area = ds[\"timeDaily_avg_iceAreaCell\"]\n",
    "ice_area.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e9d6581-da44-4d6f-9582-908d0a86581b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], shape=(31, 465044), dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ice_area.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0c376f4-a54c-489d-bd15-2130fe8eab29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates:\n",
      "    *empty*\n",
      "FrozenMappingWarningOnValuesAccess({'Time': 31, 'nCells': 465044, 'nVertices': 942873})\n"
     ]
    }
   ],
   "source": [
    "print(ds.coords)\n",
    "print(ds.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a1ea64d-21ce-4f78-810d-f1d2dab63411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406832964\n"
     ]
    }
   ],
   "source": [
    "print(str(ds.nbytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3949ea59-c1d7-410f-9bba-b02b4facb238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 407MB\n",
      "Dimensions:                       (Time: 31, nCells: 465044, nVertices: 942873)\n",
      "Dimensions without coordinates: Time, nCells, nVertices\n",
      "Data variables:\n",
      "    timeDaily_counter             (Time) int32 124B ...\n",
      "    xtime_startDaily              (Time) |S64 2kB b'2024-12-01_00:00:00' ... ...\n",
      "    xtime_endDaily                (Time) |S64 2kB ...\n",
      "    timeDaily_avg_iceAreaCell     (Time, nCells) float32 58MB 0.0 0.0 ... 0.0\n",
      "    timeDaily_avg_iceVolumeCell   (Time, nCells) float32 58MB ...\n",
      "    timeDaily_avg_snowVolumeCell  (Time, nCells) float32 58MB ...\n",
      "    timeDaily_avg_uVelocityGeo    (Time, nVertices) float32 117MB ...\n",
      "    timeDaily_avg_vVelocityGeo    (Time, nVertices) float32 117MB ...\n",
      "Attributes: (12/490)\n",
      "    case:                                                         v3.LR.histo...\n",
      "    source_id:                                                    399d430113\n",
      "    realm:                                                        seaIce\n",
      "    product:                                                      model-output\n",
      "    title:                                                        MPAS-Seaice...\n",
      "    source:                                                       E3SM Sea Ic...\n",
      "    ...                                                           ...\n",
      "    config_AM_timeSeriesStatsCustom_reference_times:              initial_time\n",
      "    config_AM_timeSeriesStatsCustom_duration_intervals:           repeat_inte...\n",
      "    config_AM_timeSeriesStatsCustom_repeat_intervals:             reset_interval\n",
      "    config_AM_timeSeriesStatsCustom_reset_intervals:              00-00-07_00...\n",
      "    config_AM_timeSeriesStatsCustom_backward_output_offset:       00-00-01_00...\n",
      "    file_id:                                                      w89d6aw0xo\n"
     ]
    }
   ],
   "source": [
    "print(ds)\n",
    "del ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e89844-e98f-4b42-b3cd-e3593ea3f151",
   "metadata": {},
   "source": [
    "# Example of Mesh File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20a8b6f4-6969-45c9-8859-709234040954",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = xr.open_dataset(\"NC_FILE_PROCESSING/mpassi.IcoswISC30E3r5.20231120.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80b4df70-fa5a-4c94-8be1-f93caae8209c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data variables:\n",
       "    edgesOnEdge        (nEdges, maxEdges2) int32 68MB ...\n",
       "    weightsOnEdge      (nEdges, maxEdges2) float64 135MB ...\n",
       "    cellsOnEdge        (nEdges, TWO) int32 11MB ...\n",
       "    verticesOnEdge     (nEdges, TWO) int32 11MB ...\n",
       "    angleEdge          (nEdges) float64 11MB ...\n",
       "    dcEdge             (nEdges) float64 11MB ...\n",
       "    dvEdge             (nEdges) float64 11MB ...\n",
       "    indexToEdgeID      (nEdges) int32 6MB ...\n",
       "    latEdge            (nEdges) float64 11MB ...\n",
       "    lonEdge            (nEdges) float64 11MB ...\n",
       "    nEdgesOnEdge       (nEdges) int32 6MB ...\n",
       "    xEdge              (nEdges) float64 11MB ...\n",
       "    yEdge              (nEdges) float64 11MB ...\n",
       "    zEdge              (nEdges) float64 11MB ...\n",
       "    fEdge              (nEdges) float64 11MB ...\n",
       "    cellsOnVertex      (nVertices, vertexDegree) int32 11MB ...\n",
       "    edgesOnVertex      (nVertices, vertexDegree) int32 11MB ...\n",
       "    kiteAreasOnVertex  (nVertices, vertexDegree) float64 23MB ...\n",
       "    areaTriangle       (nVertices) float64 8MB ...\n",
       "    indexToVertexID    (nVertices) int32 4MB ...\n",
       "    latVertex          (nVertices) float64 8MB ...\n",
       "    lonVertex          (nVertices) float64 8MB ...\n",
       "    xVertex            (nVertices) float64 8MB ...\n",
       "    yVertex            (nVertices) float64 8MB ...\n",
       "    zVertex            (nVertices) float64 8MB ...\n",
       "    fVertex            (nVertices) float64 8MB ...\n",
       "    cellsOnCell        (nCells, maxEdges) int32 11MB ...\n",
       "    edgesOnCell        (nCells, maxEdges) int32 11MB ...\n",
       "    verticesOnCell     (nCells, maxEdges) int32 11MB ...\n",
       "    areaCell           (nCells) float64 4MB ...\n",
       "    indexToCellID      (nCells) int32 2MB ...\n",
       "    latCell            (nCells) float64 4MB ...\n",
       "    lonCell            (nCells) float64 4MB ...\n",
       "    meshDensity        (nCells) float64 4MB ...\n",
       "    nEdgesOnCell       (nCells) int32 2MB ...\n",
       "    xCell              (nCells) float64 4MB ...\n",
       "    yCell              (nCells) float64 4MB ...\n",
       "    zCell              (nCells) float64 4MB ...\n",
       "    fCell              (nCells) float64 4MB ...\n",
       "    landIceMask        (Time, nCells) int32 2MB ..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh.data_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40476985-dfb0-4da2-b48e-eb2c97f74f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     5      4      0      0      0      0]\n",
      " [    12     11      9      8      0      3]\n",
      " [     4     13     12      2      0      0]\n",
      " ...\n",
      " [465043      0 465040 465041      0      0]\n",
      " [     0 465042      0 465044      0      0]\n",
      " [     0      0      0      0 465043      0]]\n"
     ]
    }
   ],
   "source": [
    "cellsOnCell = mesh[\"cellsOnCell\"].values\n",
    "print(mesh[\"cellsOnCell\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af6cbd2b-ae4f-41d4-b8c1-213fb92b3dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465044\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(mesh[\"cellsOnCell\"].max().values)\n",
    "print(mesh[\"cellsOnCell\"].min().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21202b02-d87e-4354-aea7-586babbfb900",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cellsOnCell.npy', cellsOnCell) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e0aab3b-733a-4f9f-ad63-e0a510b05cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates:\n",
      "    *empty*\n",
      "FrozenMappingWarningOnValuesAccess({'nEdges': 1408196, 'maxEdges2': 12, 'TWO': 2, 'nVertices': 942873, 'vertexDegree': 3, 'nCells': 465044, 'maxEdges': 6, 'Time': 1})\n"
     ]
    }
   ],
   "source": [
    "print(mesh.coords)\n",
    "print(mesh.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a816fde5-ec19-4430-9875-f4e8cadc10d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 509MB\n",
      "Dimensions:            (nEdges: 1408196, maxEdges2: 12, TWO: 2,\n",
      "                        nVertices: 942873, vertexDegree: 3, nCells: 465044,\n",
      "                        maxEdges: 6, Time: 1)\n",
      "Dimensions without coordinates: nEdges, maxEdges2, TWO, nVertices,\n",
      "                                vertexDegree, nCells, maxEdges, Time\n",
      "Data variables: (12/40)\n",
      "    edgesOnEdge        (nEdges, maxEdges2) int32 68MB ...\n",
      "    weightsOnEdge      (nEdges, maxEdges2) float64 135MB ...\n",
      "    cellsOnEdge        (nEdges, TWO) int32 11MB ...\n",
      "    verticesOnEdge     (nEdges, TWO) int32 11MB ...\n",
      "    angleEdge          (nEdges) float64 11MB ...\n",
      "    dcEdge             (nEdges) float64 11MB ...\n",
      "    ...                 ...\n",
      "    nEdgesOnCell       (nCells) int32 2MB ...\n",
      "    xCell              (nCells) float64 4MB ...\n",
      "    yCell              (nCells) float64 4MB ...\n",
      "    zCell              (nCells) float64 4MB ...\n",
      "    fCell              (nCells) float64 4MB ...\n",
      "    landIceMask        (Time, nCells) int32 2MB ...\n",
      "Attributes: (12/1313)\n",
      "    model_name:                                                      mpas\n",
      "    core_name:                                                       ocean\n",
      "    source:                                                          MPAS\n",
      "    Conventions:                                                     MPAS\n",
      "    git_version:                                                     v2.1.0-1...\n",
      "    on_a_sphere:                                                     YES\n",
      "    ...                                                              ...\n",
      "    MPAS_Mesh_NCO_Version:                                           5.1.9\n",
      "    MPAS_Mesh_ESMF_Version:                                          8.4.2\n",
      "    MPAS_Mesh_geometric_features_Version:                            1.3.0\n",
      "    MPAS_Mesh_Metis_Version:                                         5.1.1\n",
      "    MPAS_Mesh_pyremap_Version:                                       1.2.0\n",
      "    NCO:                                                             netCDF O...\n"
     ]
    }
   ],
   "source": [
    "print(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4dd0dbf8-f761-4e60-a369-e0c6f2f9a03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508623836\n"
     ]
    }
   ],
   "source": [
    "print(str(mesh.nbytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fff3ae1-5dc1-4ac7-af6d-eaa97bee17e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03679cef-dfd2-46e8-9dfe-6c9b519add06",
   "metadata": {},
   "source": [
    "# Pre-processing + Freeboard calculation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1de9a215-6126-459b-8df2-3842efb187ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants (adjust if you use different units)\n",
    "D_WATER = 1023  # Density of seawater (kg/m^3)\n",
    "D_ICE = 917     # Density of sea ice (kg/m^3)\n",
    "D_SNOW = 330    # Density of snow (kg/m^3)\n",
    "\n",
    "MIN_AREA = 1e-6\n",
    "\n",
    "def compute_freeboard(area: np.ndarray, \n",
    "                      ice_volume: np.ndarray, \n",
    "                      snow_volume: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute sea ice freeboard from ice and snow volume and area.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    area : np.ndarray\n",
    "        Sea ice concentration / area (same shape as ice_volume and snow_volume).\n",
    "    ice_volume : np.ndarray\n",
    "        Sea ice volume per grid cell.\n",
    "    snow_volume : np.ndarray\n",
    "        Snow volume per grid cell.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    freeboard : np.ndarray\n",
    "        Freeboard height for each cell, same shape as inputs.\n",
    "    \"\"\"\n",
    "    # Initialize arrays\n",
    "    height_ice = np.zeros_like(ice_volume)\n",
    "    height_snow = np.zeros_like(snow_volume)\n",
    "\n",
    "    # Valid mask: avoid dividing by very small or zero area\n",
    "    valid = area > MIN_AREA\n",
    "\n",
    "    # Safely compute heights where valid\n",
    "    height_ice[valid] = ice_volume[valid] / area[valid]\n",
    "    height_snow[valid] = snow_volume[valid] / area[valid]\n",
    "\n",
    "    # Compute freeboard using the physical formula\n",
    "    freeboard = (\n",
    "        height_ice * (D_WATER - D_ICE) / D_WATER +\n",
    "        height_snow * (D_WATER - D_SNOW) / D_WATER\n",
    "    )\n",
    "\n",
    "    return freeboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a739e27-622f-4a24-b031-270622c5710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_freeboard(freeboard, min_val=-0.2, max_val=1.2):\n",
    "    return np.clip((freeboard - min_val) / (max_val - min_val), 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f5856f-e996-4eee-b5aa-941ccd127b88",
   "metadata": {},
   "source": [
    "# Custom Pytorch Dataset\n",
    "\n",
    "Example from NERSC of using ERA5 Dataset:\n",
    "https://github.com/NERSC/dl-at-scale-training/blob/main/utils/data_loader.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7df3ff-a8ea-46cc-9053-97bfbb41cea8",
   "metadata": {},
   "source": [
    "## Constants\n",
    "\n",
    "TRY: NUM_WORKERS as 16 to 32 - profile to see if the GPU is still waiting on the CPU.\n",
    "\n",
    "TRY: NUM_WORKERS as 64 - the number of CPU cores available.\n",
    "\n",
    "TRY: NUM_WORKERS experiment with os.cpu_count() - 2\n",
    "\n",
    "TRY: NUM_WORKERS experiment with (logical_cores_per_gpu * num_gpus)\n",
    "\n",
    "num_workers considerations:\n",
    "Too few workers: GPUs might become idle waiting for data.\n",
    "Too many workers: Can lead to increased CPU memory usage and context switching overhead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "646812d0-b13a-4fff-a261-9fb5f6835cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORKERS = 64\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f2488a-5e61-4012-9a47-9f231de6ecd2",
   "metadata": {},
   "source": [
    "# __ init __ - masks and loads the data into tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "381e4d81-da70-4886-869a-7e69db40fead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from typing import List, Union, Callable, Tuple\n",
    "from NC_FILE_PROCESSING.patchify_utils import patchify_by_latlon_spillover\n",
    "from perlmutterpath import * # Contains the data_dir and mesh_dir variables\n",
    "\n",
    "import logging\n",
    "\n",
    "# Set level to logging.INFO to see the statements\n",
    "logging.basicConfig(filename='DailyNetCDFDataset.log', filemode='w', level=logging.INFO)\n",
    "\n",
    "class DailyNetCDFDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset that concatenates a directory of month-wise NetCDF files\n",
    "    along their 'Time' dimension and yields daily data *plus* its timestamp.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dir : str\n",
    "        Directory containing NetCDF files\n",
    "    transform : Callable | None\n",
    "        Optional transform applied to the data tensor *only*.\n",
    "    decode_time : bool\n",
    "        Let xarray convert CF-style time coordinates to np.datetime64.\n",
    "    drop_missing : bool\n",
    "        If True, drops any days where one of the requested variables is missing.\n",
    "    latitude_threshold\n",
    "        The minimum latitude to use for Artic data\n",
    "    context_length\n",
    "        The number of days to fetch for input in the prediction step\n",
    "    forecast_horizon\n",
    "        The number of days to predict in the future\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str = data_dir,\n",
    "        mesh_dir: str = mesh_dir,\n",
    "        transform: Callable = None,\n",
    "        decode_time: bool = True,\n",
    "        drop_missing: bool = True,\n",
    "        latitude_threshold = 40,\n",
    "        context_length = 7,\n",
    "        forecast_horizon = 1\n",
    "    ):\n",
    "\n",
    "        \"\"\" __init__ needs to \n",
    "\n",
    "        Handle the raw data:\n",
    "        1) Gather the sorted daily data from each netCDF file (1 file = 1 month of daily data)\n",
    "            The netCDF files contain nCells worth of data per day for each feature (ice area, ice volume, etc.)\n",
    "            nCells = 465044 with the IcoswISC30E3r5 mesh\n",
    "        2) Store the datetime information from each nCells array from the daily data\n",
    "        3) Extract raw data\n",
    "        \n",
    "        Perform pre-processing:\n",
    "        4) Apply a mask to nCells to look just at regions in certain latitudes\n",
    "            nCells >= 40 degrees is 53973 cells\n",
    "            nCells >= 50 degrees is 35623 cells\n",
    "        5) Derive Freeboard from ice area, snow volume, and ice volume\n",
    "        6) Custom patchify and store patch_ids so the data loader can use them\n",
    "        7) Concatenate the data across Time\n",
    "        8) Normalize the data (Ice area is already between 0 and 1; Freeboard is not) \"\"\"\n",
    "\n",
    "        start_time = time.time()\n",
    "        self.transform = transform\n",
    "        self.context_length = context_length\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "\n",
    "        # --- 1. Gather files (sorted for deterministic order) ---------\n",
    "        self.data_dir = data_dir\n",
    "        self.file_paths = sorted(\n",
    "            [\n",
    "                os.path.join(data_dir, f)\n",
    "                for f in os.listdir(data_dir)\n",
    "                if f.endswith(\".nc\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # TODO: USE THIS FOR THE FULL DATASET (OR JUST A CERTAIN CENTURY, LIKE 18--)\n",
    "        # self.data_dir = data_dir\n",
    "        # self.file_paths = sorted(\n",
    "        #     [\n",
    "        #         os.path.join(data_dir, f)\n",
    "        #         for f in os.listdir(data_dir)\n",
    "        #         if f.startswith(\"v3.LR.historical_0051.mpassi.hist.am.timeSeriesStatsDaily.18\") and f.endswith(\".nc\")\n",
    "        #     ]\n",
    "        # )\n",
    "        \n",
    "        logging.info(f\"Found {len(self.file_paths)} NetCDF files:\")\n",
    "        # for f in self.file_paths:\n",
    "        #     logging.info(f\"  - {f}\")     # Print all the file names in the folder\n",
    "\n",
    "        if not self.file_paths:\n",
    "            raise FileNotFoundError(f\"No *.nc files found in {data_dir!r}\")\n",
    "        \n",
    "        # --- 2. Store a list of datetimes from each file -> helps with retrieving 1 day's data later\n",
    "        all_times = []\n",
    "        for path in self.file_paths:\n",
    "            ds = xr.open_dataset(path)\n",
    "        \n",
    "            # Decode byte strings and fix the format\n",
    "            xtime_strs = ds[\"xtime_startDaily\"].str.decode(\"utf-8\").values\n",
    "            xtime_strs = [s.replace(\"_\", \" \") for s in xtime_strs]  # \"0010-01-01_00:00:00\" → \"0010-01-01 00:00:00\"\n",
    "        \n",
    "            # Convert to datetime.datetime objects\n",
    "            times = [datetime.strptime(s, \"%Y-%m-%d %H:%M:%S\") for s in xtime_strs]\n",
    "            all_times.extend(times)\n",
    "        \n",
    "        # Store in self.times\n",
    "        self.times = all_times\n",
    "        self.times = np.array(self.times, dtype='datetime64[s]')\n",
    "        #self.times = cudf.to_datetime(all_times)\n",
    "\n",
    "        print(f\"DEBUG: self.times shape in __init__: {self.times.shape}\")\n",
    "        print(f\"DEBUG: self.times dtype in __init__: {self.times.dtype}\")\n",
    "\n",
    "        # Checking the dates\n",
    "        logging.info(f\"Parsed {len(self.times)} total dates\")\n",
    "        logging.info(f\"First few: {str(self.times[:5])}\")\n",
    "\n",
    "        # Stats on how many dates there are\n",
    "        logging.info(f\"Total days collected: {len(self.times)}\")\n",
    "        logging.info(f\"Unique days: {len(np.unique(self.times))}\")\n",
    "        logging.info(f\"First 35 days: {self.times[:35]}\")\n",
    "        logging.info(f\"Last 35 days: {self.times[-35:]}\")\n",
    "\n",
    "        # Load the mesh file. Latitudes and Longitudes are in radians.\n",
    "        mesh = xr.open_dataset(mesh_dir)\n",
    "        latCell = np.degrees(mesh[\"latCell\"].values)\n",
    "        lonCell = np.degrees(mesh[\"lonCell\"].values)\n",
    "        self.cell_mask = latCell >= latitude_threshold\n",
    "        logging.info(f\"Mask size: {np.count_nonzero(self.cell_mask)}\")\n",
    "\n",
    "        self.full_to_masked = {\n",
    "            full_idx: new_idx\n",
    "            for new_idx, full_idx in enumerate(np.where(self.cell_mask)[0])\n",
    "        }\n",
    "\n",
    "        # Also store reverse mapping: masked -> full for recovery of data later\n",
    "        self.masked_to_full = {\n",
    "            v: k for k, v in self.full_to_masked.items()\n",
    "        }\n",
    "\n",
    "        # --- 3. Extract raw data \n",
    "        freeboard_all = []\n",
    "        ice_area_all = []\n",
    "\n",
    "        for path in self.file_paths:\n",
    "            ds = xr.open_dataset(path)\n",
    "\n",
    "            # Extract raw data\n",
    "            area = ds[\"timeDaily_avg_iceAreaCell\"].values\n",
    "            ice_volume = ds[\"timeDaily_avg_iceVolumeCell\"].values\n",
    "            snow_volume = ds[\"timeDaily_avg_snowVolumeCell\"].values\n",
    "\n",
    "            # --- 4. Apply a mask to the nCells\n",
    "            area = area[:, self.cell_mask]\n",
    "            ice_volume = ice_volume[:, self.cell_mask]\n",
    "            snow_volume = snow_volume[:, self.cell_mask]\n",
    "\n",
    "            # --- 5. Derive Freeboard from ice area, snow volume and ice volume\n",
    "            freeboard = compute_freeboard(area, ice_volume, snow_volume)\n",
    "\n",
    "            # These will be deleted later to save space\n",
    "            freeboard_all.append(freeboard) \n",
    "            ice_area_all.append(area)\n",
    "\n",
    "        # --- 6. Custom patchify function\n",
    "        #     Returns \n",
    "        # full_nCells_patch_ids : np.ndarray\n",
    "        #     Array of shape (nCells,) giving patch ID or -1 if unassigned.\n",
    "        # indices_per_patch_id : List[np.ndarray]\n",
    "        #     List of patches, each a list of cell indices (np.ndarray of ints) that correspond with nCells array.\n",
    "        # patch_latlons : np.ndarray\n",
    "        #     Array of shape (n_patches, 2) containing (latitude, longitude) for one\n",
    "        #     representative cell per patch (the first cell added to the patch)\n",
    "        #     The intention is to use this for positional encoding later\n",
    "        self.full_nCells_patch_ids, self.indices_per_patch_id, self.patch_latlons = patchify_by_latlon_spillover(\n",
    "            latCell, lonCell, k=256, max_patches=140, lat_threshold=latitude_threshold)\n",
    "\n",
    "        logging.info(f\"Longitude and latitude array shape: {self.patch_latlons.shape} should be (n_patches, 2)\")\n",
    "        logging.info(f\"Minimum latitude:  {np.min(self.patch_latlons, axis=0)[0]}\")\n",
    "        logging.info(f\"Maximum latitude:  {np.max(self.patch_latlons, axis=0)[0]}\")\n",
    "        logging.info(f\"Minimum longitude: {np.min(self.patch_latlons, axis=0)[1]}\")\n",
    "        logging.info(f\"Maximum longitude: {np.max(self.patch_latlons, axis=0)[1]}\")\n",
    "        logging.info(f\"Should be between lat_threshold and 90 degrees for latitude\")\n",
    "        logging.info(f\"Should be between 0 and 360 degrees for longitude\")\n",
    "        \n",
    "        # Convert full-domain patch indices to masked-domain indices\n",
    "        # This ensures there's no out of bounds problem,\n",
    "        # liks index 296237 is out of bounds for axis 1 with size 53973\n",
    "        self.indices_per_patch_id = [\n",
    "            [self.full_to_masked[i] for i in patch if i in self.full_to_masked]\n",
    "            for patch in self.indices_per_patch_id\n",
    "        ]\n",
    "\n",
    "        # --- 7. Concatenate the data across Time\n",
    "        # Concatenate across time\n",
    "        self.freeboard = np.concatenate(freeboard_all, axis=0)  # (T, nCells)\n",
    "        self.ice_area = np.concatenate(ice_area_all, axis=0)    # (T, nCells)\n",
    "\n",
    "        # Discard the lists that are not needed anymore -- save space\n",
    "        del freeboard_all, ice_area_all\n",
    "\n",
    "        # --- 8. Normalize the data (Area is already between 0 and 1; Freeboard is not)\n",
    "        self.freeboard_min = self.freeboard[0].min()\n",
    "        self.freeboard_max = self.freeboard[0].max()\n",
    "        \n",
    "        logging.info(f\"Freeboard min: {self.freeboard_min}\" )\n",
    "        logging.info(f\"Freeboard max: {self.freeboard_max}\")\n",
    "\n",
    "        self.freeboard = normalize_freeboard(\n",
    "            self.freeboard, min_val=self.freeboard_min, max_val=self.freeboard_max)\n",
    "\n",
    "        logging.info(f\"Freeboard Shape: {self.freeboard.shape}\")\n",
    "        logging.info(f\"Ice Area Shape:  {self.ice_area.shape}\")\n",
    "\n",
    "        logging.info(\"=== Normalized Freeboard ===\")\n",
    "\n",
    "        freeboard_min_after_norm = self.freeboard[0].min()\n",
    "        freeboard_max_after_norm  = self.freeboard[0].max()\n",
    "        \n",
    "        logging.info(f\"Freeboard min: {freeboard_min_after_norm}\" )\n",
    "        logging.info(f\"Freeboard max: {freeboard_max_after_norm}\")\n",
    "\n",
    "        logging.info(\"End of __init__\")\n",
    "        \n",
    "        end_time = time.time()\n",
    "        logging.info(f\"Elapsed time: {end_time - start_time} seconds\")\n",
    "\n",
    "        print(f\"DEBUG INIT: Type of self.times: {type(self.times)}\")\n",
    "        if hasattr(self.times, 'shape'):\n",
    "            print(f\"DEBUG INIT: Shape of self.times: {self.times.shape}\")\n",
    "        if hasattr(self.times, 'dtype'):\n",
    "            print(f\"DEBUG INIT: Dtype of self.times: {self.times.dtype}\")\n",
    "        if len(self.times) > 0:\n",
    "            print(f\"DEBUG INIT: Type of self.times[0]: {type(self.times[0])}\")\n",
    "            if hasattr(self.times[0], 'shape'):\n",
    "                print(f\"DEBUG INIT: Shape of self.times[0]: {self.times[0].shape}\")\n",
    "            if hasattr(self.times[0], 'dtype'):\n",
    "                print(f\"DEBUG INIT: Dtype of self.times[0]: {self.times[0].dtype}\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns the total number of possible starting indices (idx) for a valid sequence.\n",
    "        A valid sequence needs `self.context_length` days for input and `self.forecast_horizon` days for target.\n",
    "        \n",
    "        ex) If the total number of days is 365, the context_length is 7 and the forecast_horizon is 3, then\n",
    "        last valid starting index = total days - (context length + forecast horizon) + 1\n",
    "        365 - (7 + 3) + 1 = 365 - 10 + 1 = 356 valid starting indices\n",
    "        \"\"\"\n",
    "        required_length = self.context_length + self.forecast_horizon\n",
    "        if len(self.freeboard) < required_length:\n",
    "            return 0 # Not enough raw data to form even one sample\n",
    "\n",
    "        # The total number of valid starting indices\n",
    "        return len(self.freeboard) - required_length + 1\n",
    "\n",
    "    def get_patch_tensor(self, day_idx: int) -> torch.Tensor:\n",
    "        \n",
    "        \"\"\"\n",
    "        Retrieves the feature data for a specific day, organized into patches.\n",
    "\n",
    "        This method extracts 'freeboard' and 'ice_area' data for a given day\n",
    "        and then reshapes it according to the pre-defined patches. Each patch\n",
    "        will contain its own set of feature values.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        day_idx : int\n",
    "            The integer index of the day to retrieve data for, relative to the\n",
    "            concatenated dataset's time dimension.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            A tensor containing the feature data organized by patches for the\n",
    "            specified day.\n",
    "            Shape: (num_patches, num_features, patch_size)\n",
    "            Where:\n",
    "            - num_patches: Total number of patches (ex., 140).\n",
    "            - num_features: The number of features per cell (currently 2: freeboard, ice_area).\n",
    "            - patch_size: The number of cells within each patch.\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        freeboard_day = self.freeboard[day_idx]  # (nCells,)\n",
    "        ice_area_day = self.ice_area[day_idx]    # (nCells,)\n",
    "        features = np.stack([freeboard_day, ice_area_day], axis=0)  # (2, nCells)\n",
    "        patch_tensors = []\n",
    "\n",
    "        for patch_indices in self.indices_per_patch_id:\n",
    "            patch = features[:, patch_indices]  # (2, patch_size)\n",
    "            patch_tensors.append(torch.tensor(patch, dtype=torch.float32))\n",
    "\n",
    "        return torch.stack(patch_tensors)  # (context_length, num_patches, num_features, patch_size)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, int, int, int, int, int, int, int]:\n",
    "        \"\"\"__ getitem __ needs to \n",
    "        \n",
    "        1. Given an input of a certain date id, get the input and the target tensors\n",
    "        2. Return all the patches for the input and the target\n",
    "           Features are: [freeboard, ice_area] over masked cells. \n",
    "           \n",
    "        \"\"\"\n",
    "        # Start with the id of the day in question\n",
    "        start_idx = idx\n",
    "\n",
    "        # Extract datetime object for the start of the sequence\n",
    "        start_date_np = self.times[start_idx]\n",
    "        start_date_dt = start_date_np.astype(datetime)\n",
    "\n",
    "        year = start_date_dt.year\n",
    "        month = start_date_dt.month\n",
    "        day = start_date_dt.day\n",
    "\n",
    "        # end_idx is the exclusive end of the input sequence,\n",
    "        # and the inclusive start of the target sequence.\n",
    "        end_idx = idx + self.context_length\n",
    "        target_start = end_idx\n",
    "\n",
    "        # the target sequence ends after forecast horizon\n",
    "        target_end = end_idx + self.forecast_horizon\n",
    "\n",
    "        if target_end > len(self.freeboard):\n",
    "            raise IndexError(\n",
    "                f\"Requested time window exceeds dataset. \"\n",
    "                f\"Problematic idx: {idx}, \"\n",
    "                f\"Context Length: {self.context_length}, \"\n",
    "                f\"Forecast Horizon: {self.forecast_horizon}, \"\n",
    "                f\"Calculated target_end: {target_end}, \"\n",
    "                f\"Actual dataset length (len(self.freeboard)): {len(self.freeboard)}\"\n",
    "            )\n",
    "\n",
    "        # Build input tensor\n",
    "        input_seq = [self.get_patch_tensor(i) for i in range(start_idx, end_idx)]\n",
    "        input_tensor = torch.stack(input_seq)\n",
    "    \n",
    "        # Build target tensor: shape (forecast_horizon, num_patches)\n",
    "        target_seq = self.ice_area[end_idx:target_end]\n",
    "        target_patches = []\n",
    "        for daily_data in target_seq:\n",
    "            patch_day = [\n",
    "                torch.tensor(daily_data[patch_indices]) for patch_indices in self.indices_per_patch_id\n",
    "            ]\n",
    "            \n",
    "            # After stacking, patch_day_tensor will be (num_patches, CELLS_PER_PATCH)\n",
    "            patch_day_tensor = torch.stack(patch_day)  # (num_patches,)\n",
    "            target_patches.append(patch_day_tensor)\n",
    "\n",
    "        # Final target tensor shape: (forecast_horizon, num_patches, CELLS_PER_PATCH), ex. [3, 140, 256]\n",
    "        target_tensor = torch.stack(target_patches)\n",
    "        \n",
    "        return (\n",
    "            input_tensor,\n",
    "            target_tensor,\n",
    "            start_idx,\n",
    "            end_idx,\n",
    "            target_start,\n",
    "            target_end,\n",
    "            year,   # for positional encoding\n",
    "            month,  # for positional encoding\n",
    "            day     # for positional encoding\n",
    "        )\n",
    "        \n",
    "    def __repr__(self):\n",
    "        \"\"\" Format the string representation of the data \"\"\"\n",
    "        return (\n",
    "            f\"<DailyNetCDFDataset: {len(self)} days, \"\n",
    "            f\"{len(self.freeboard[0])} cells/day, \"\n",
    "            f\"{len(self.file_paths)} files loaded>\"\n",
    "        )\n",
    "\n",
    "    def time_to_dataframe(self) -> pd.DataFrame:\n",
    "            \"\"\"Return a DataFrame of time features you can merge with predictions.\"\"\"\n",
    "            t = pd.to_datetime(self.times)            # pandas Timestamp index\n",
    "            return pd.DataFrame(\n",
    "                {\n",
    "                    \"time\": t,\n",
    "                    \"year\": t.year,\n",
    "                    \"month\": t.month,\n",
    "                    \"day\": t.day,\n",
    "                    \"doy\": t.dayofyear,\n",
    "                }\n",
    "            )\n",
    "\n",
    "# --- Custom Collate Function ---\n",
    "def custom_collate_fn(batch: List[Tuple]) -> Tuple:\n",
    "    \"\"\"\n",
    "    Custom collate function to handle the specific output of DailyNetCDFDataset.__getitem__.\n",
    "    Ensures that year, month, and day are batched as (B,) tensors.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- DEBUG: Inside custom_collate_fn ---\")\n",
    "    \n",
    "    transposed_batch = list(zip(*batch))\n",
    "\n",
    "    # Debug prints for the raw lists before torch.tensor()\n",
    "    print(f\"COLLECTED BATCH SIZE: {len(batch)}\")\n",
    "    print(f\"TYPE OF TRANSPOSED_BATCH[6] (years list): {type(transposed_batch[6])}\")\n",
    "    print(f\"TYPE OF TRANSPOSED_BATCH[7] (months list): {type(transposed_batch[7])}\")\n",
    "    print(f\"TYPE OF TRANSPOSED_BATCH[8] (days list): {type(transposed_batch[8])}\")\n",
    "\n",
    "    if len(transposed_batch[8]) > 0:\n",
    "        print(f\"FIRST ELEMENT OF DAYS LIST: {transposed_batch[8][0]}\")\n",
    "        print(f\"TYPE OF FIRST ELEMENT OF DAYS LIST: {type(transposed_batch[8][0])}\")\n",
    "        if isinstance(transposed_batch[8][0], np.ndarray):\n",
    "            print(f\"SHAPE OF FIRST ELEMENT (if numpy array): {transposed_batch[8][0].shape}\")\n",
    "        elif isinstance(transposed_batch[8][0], torch.Tensor):\n",
    "            print(f\"SHAPE OF FIRST ELEMENT (if torch tensor): {transposed_batch[8][0].shape}\")\n",
    "    \n",
    "    # Collate input_tensor and target_tensor\n",
    "    input_tensors = torch.stack(transposed_batch[0])\n",
    "    target_tensors = torch.stack(transposed_batch[1])\n",
    "\n",
    "    # Collate scalar integers (start_idx, end_idx, target_start, target_end, year, month, day)\n",
    "    start_indices = torch.tensor(transposed_batch[2], dtype=torch.long)\n",
    "    end_indices = torch.tensor(transposed_batch[3], dtype=torch.long)\n",
    "    target_starts = torch.tensor(transposed_batch[4], dtype=torch.long)\n",
    "    target_ends = torch.tensor(transposed_batch[5], dtype=torch.long)\n",
    "    \n",
    "    years = torch.tensor(transposed_batch[6], dtype=torch.long)\n",
    "    months = torch.tensor(transposed_batch[7], dtype=torch.long)\n",
    "    days = torch.tensor(transposed_batch[8], dtype=torch.long)\n",
    "\n",
    "    print(f\"DEBUG: Shape of years AFTER COLLATING: {years.shape}\")\n",
    "    print(f\"DEBUG: Shape of months AFTER COLLATING: {months.shape}\")\n",
    "    print(f\"DEBUG: Shape of days AFTER COLLATING: {days.shape}\")\n",
    "    print(\"--- END DEBUG: Inside custom_collate_fn ---\\n\")\n",
    "\n",
    "    return (\n",
    "        input_tensors,\n",
    "        target_tensors,\n",
    "        start_indices,\n",
    "        end_indices,\n",
    "        target_starts,\n",
    "        target_ends,\n",
    "        years,\n",
    "        months,\n",
    "        days\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5972aabe-4e3e-4062-ab72-15c8318018b5",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19b03083-9694-4237-b348-092ef3506ee3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Making the Dataset Class ===== \n",
      "DEBUG: self.times shape in __init__: (365,)\n",
      "DEBUG: self.times dtype in __init__: datetime64[s]\n",
      "Built 140 patches of size ~256\n",
      "Cluster sizes:\n",
      "min size 256\n",
      "max size 429204\n",
      "smallest count (np.int64(0), 256)\n",
      "max count (np.int64(-1), 429204)\n",
      "number of patches: 141\n",
      "DEBUG INIT: Type of self.times: <class 'numpy.ndarray'>\n",
      "DEBUG INIT: Shape of self.times: (365,)\n",
      "DEBUG INIT: Dtype of self.times: datetime64[s]\n",
      "DEBUG INIT: Type of self.times[0]: <class 'numpy.datetime64'>\n",
      "DEBUG INIT: Shape of self.times[0]: ()\n",
      "DEBUG INIT: Dtype of self.times[0]: datetime64[s]\n",
      "Training data length:    249\n",
      "Validation data length:  53\n",
      "Testing data length:     54\n",
      "Total days =  356\n",
      "Number of training batches 15.5625\n",
      "Number of validation batches 3.3125\n",
      "Number of test batches after drop_last incomplete batch 3\n",
      "Number of test days to drop after drop_last incomplete batch 3\n",
      "===== Printing Dataset ===== \n",
      "<DailyNetCDFDataset: 356 days, 53973 cells/day, 12 files loaded>\n",
      "Fetched start index 0: Time=0010-01-01T00:00:00\n",
      "Fetched end   index 7: Time=0010-01-08T00:00:00\n",
      "Fetched target start index 7: Time=0010-01-08T00:00:00\n",
      "Fetched target end   index 10: Time=0010-01-11T00:00:00\n",
      "===== Starting DataLoader ====\n",
      "input_tensor should be of shape (context_length, num_patches, num_features, patch_size)\n",
      "actual input_tensor.shape = torch.Size([7, 140, 2, 256])\n",
      "target_tensor should be of shape (forecast_horizon, num_patches, patch_size)\n",
      "actual target_tensor.shape = torch.Size([3, 140, 256])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "print(\"===== Making the Dataset Class ===== \")\n",
    "\n",
    "# load all the data from one folder\n",
    "dataset = DailyNetCDFDataset(data_dir, forecast_horizon=3)\n",
    "\n",
    "total_days = len(dataset)\n",
    "train_end = int(total_days * 0.7)\n",
    "val_end = int(total_days * 0.85)\n",
    "\n",
    "train_set = Subset(dataset, range(0, train_end))\n",
    "val_set   = Subset(dataset, range(train_end, val_end))\n",
    "test_set  = Subset(dataset, range(val_end, total_days))\n",
    "\n",
    "print(\"Training data length:   \", len(train_set))\n",
    "print(\"Validation data length: \", len(val_set))\n",
    "print(\"Testing data length:    \", len(test_set))\n",
    "\n",
    "total_days = len(train_set) + len(val_set) + len(test_set)\n",
    "print(\"Total days = \", total_days)\n",
    "\n",
    "print(\"Number of training batches\", len(train_set)/BATCH_SIZE)\n",
    "print(\"Number of validation batches\", len(val_set)/BATCH_SIZE)\n",
    "\n",
    "print(\"Number of test batches after drop_last incomplete batch\", int(len(test_set)/BATCH_SIZE))\n",
    "print(\"Number of test days to drop after drop_last incomplete batch\", len(test_set)//BATCH_SIZE)\n",
    "\n",
    "print(\"===== Printing Dataset ===== \")\n",
    "print(dataset)                 # calls __repr__ → see how many files & days loaded\n",
    "\n",
    "# Get a sample\n",
    "input_tensor, target_tensor, start_idx, end_idx, target_start, target_end, year, month, day = dataset[0]\n",
    "\n",
    "print(f\"Fetched start index {start_idx}: Time={dataset.times[start_idx]}\")\n",
    "print(f\"Fetched end   index {end_idx}: Time={dataset.times[end_idx]}\")\n",
    "\n",
    "print(f\"Fetched target start index {target_start}: Time={dataset.times[target_start]}\")\n",
    "print(f\"Fetched target end   index {target_end}: Time={dataset.times[target_end]}\")\n",
    "\n",
    "print(\"===== Starting DataLoader ====\")\n",
    "# wrap in a DataLoader\n",
    "# 1. Use pinned memory for faster asynch transfer to GPUs)\n",
    "# 2. Use a prefetch factor so that the GPU is fed w/o a ton of CPU memory use\n",
    "# 3. Use shuffle=False to preserve time order (especially for forecasting)\n",
    "# 4. Use drop_last=True to prevent it from testing on incomplete batches\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True, prefetch_factor=2)\n",
    "val_loader   = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True, prefetch_factor=2)\n",
    "test_loader  = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True, prefetch_factor=2, drop_last=True)\n",
    "\n",
    "print(\"input_tensor should be of shape (context_length, num_patches, num_features, patch_size)\")\n",
    "print(f\"actual input_tensor.shape = {input_tensor.shape}\")\n",
    "print(\"target_tensor should be of shape (forecast_horizon, num_patches, patch_size)\")\n",
    "print(f\"actual target_tensor.shape = {target_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965199f2-b321-4e6f-bc64-413627db789b",
   "metadata": {},
   "source": [
    "# Positional Encoder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c66251a-83f8-4089-a7a1-c25185bc4dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CombinedPositionalEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A positional encoder that combines temporal (date-based) and spatial (lat/lon-based)\n",
    "    positional embeddings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    d_model : int\n",
    "        The dimension of the model's hidden states (embedding dimension).\n",
    "    max_time_idx : int\n",
    "        The maximum possible integer index for the start date in the dataset.\n",
    "        This determines the size of the temporal embedding lookup table.\n",
    "    patch_latlons : torch.Tensor\n",
    "        A tensor of shape (num_patches, 2) where the second dimension contains\n",
    "        [latitude, longitude] for each patch.\n",
    "    dropout : float, optional\n",
    "        Dropout rate to apply to the combined positional embeddings. Defaults to 0.1.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, patch_latlons: torch.Tensor, lat_threshold: float, dropout: float = 0.1):    \n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_patches = patch_latlons.shape[0] # Get num_patches from patch_latlons\n",
    "\n",
    "        # Ensure d_model is even, as both temporal and spatial components rely on even splits.\n",
    "        if d_model % 2 != 0:\n",
    "            raise ValueError(\"d_model must be an even number for this positional encoding setup.\")\n",
    "        \n",
    "        # Allocate dimensions for time and space\n",
    "        # A common approach is to split d_model evenly or by importance.\n",
    "        # Divide up the dimensions 50/50 for spatial and temporal positional encoding.\n",
    "        d_model_temporal_total = d_model // 2\n",
    "        d_model_spatial_total = d_model // 2 # d_model is even, so this will be even\n",
    "\n",
    "        # Ensure temporal total dimensions are sufficient and can be split into even parts.\n",
    "        # Each of year, month, day needs at least 2 dimensions for sinusoidal encoding.\n",
    "        if d_model_temporal_total < 6:\n",
    "            raise ValueError(\"d_model_temporal_total must be at least 6 to ensure even splits for year, month, day.\")\n",
    "\n",
    "        # Strategy:\n",
    "        # 1. Sinusoidal for (year, month, day) separately, each producing a small vector.\n",
    "        # 2. Concatenate these small vectors to form a `temporal_encoding_vector`.\n",
    "        # 3. Apply a linear layer: `nn.Linear(sum_of_small_vectors, d_model)` to project to `d_model`.\n",
    "    \n",
    "        # Allocate temporal dimensions, ensuring each is even.\n",
    "        # This strategy ensures all three components are even, distributing any remainder\n",
    "        # from `d_model_temporal_total // 6` to the `d_model_day`.\n",
    "        self.d_model_year = 2 * (d_model_temporal_total // 6)\n",
    "        self.d_model_month = 2 * (d_model_temporal_total // 6)\n",
    "        self.d_model_day = d_model_temporal_total - (self.d_model_year + self.d_model_month) # Assign remainder\n",
    "\n",
    "        # Sanity check: Ensure the calculated dimensions are indeed even.\n",
    "        # This check should pass with the above logic.\n",
    "        if self.d_model_year % 2 != 0 or self.d_model_month % 2 != 0 or self.d_model_day % 2 != 0:\n",
    "            raise RuntimeError(\"Internal error: Temporal dimension allocation resulted in odd dimensions.\")\n",
    "\n",
    "        # Initialize spatial encoding module\n",
    "        # Its d_model parameter is the total dimensions for lat + lon, which is d_model_spatial_total.\n",
    "        self.spatial_encoding_module = LatLonPositionalEncoding(\n",
    "            d_model=d_model_spatial_total, # This is the total for lat + lon\n",
    "            patch_latlons=patch_latlons,\n",
    "            lat_threshold=lat_threshold\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Base frequencies or Divisors for sinusoidal encoding. Larger values for more distinct features.\n",
    "        # TODO: Adjust these based on the expected range of year, month, day values\n",
    "        # For year, often a larger base (e.g., 10000.0)\n",
    "        # For month, max 12\n",
    "        # For day, max 31\n",
    "        self.year_div_term_base = 10000.0 # Standard for larger range indices\n",
    "        self.month_div_term_base = 1000.0 # Smaller range than year\n",
    "        self.day_div_term_base = 100.0    # Smallest range\n",
    "\n",
    "    def _generate_sinusoidal_encoding(self, positions: torch.Tensor, dim: int, div_base: float) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Generates sinusoidal positional encoding for a single component (e.g., year, month, day).\n",
    "        Expects 'dim' to always be an even number.\n",
    "        \"\"\"\n",
    "        if dim == 0: return torch.empty(positions.shape[0], 0, device=positions.device) # Handle zero-dim case\n",
    "        if dim % 2 != 0:\n",
    "            # This check should ideally not be hit if __init__ logic is correct.\n",
    "            raise ValueError(f\"Dim ({dim}) must be an even number for sinusoidal encoding.\")\n",
    "\n",
    "        position = positions.unsqueeze(1) # (B, 1)\n",
    "        \n",
    "        # Calculate div_term to spread frequencies across the 'dim' dimensions\n",
    "        # div_term has dim/2 elements, matching the slices\n",
    "        div_term = torch.exp(torch.arange(0, dim, 2, device=positions.device) * -(np.log(div_base) / dim))\n",
    "        \n",
    "        pe = torch.zeros(positions.shape[0], dim, device=positions.device)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x: torch.Tensor,\n",
    "                years: torch.Tensor, months: torch.Tensor, days: torch.Tensor,\n",
    "                context_length: int) -> torch.Tensor:\n",
    "        \n",
    "        \"\"\"\n",
    "        Adds temporal (year, month, day) and spatial (lat/lon) positional encodings.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input from patch_embed, shape (B, T*P, d_model).\n",
    "                Here, B=Batch size, T=Context length, P=Number of patches.\n",
    "            years (torch.Tensor): Batch of year values, shape (B,).\n",
    "            months (torch.Tensor): Batch of month values, shape (B,).\n",
    "            days (torch.Tensor): Batch of day values, shape (B,).\n",
    "            context_length (int): The T (time steps) dimension of the input sequence.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Tensor with combined positional encodings added, shape (B, T*P, d_model).\n",
    "        \"\"\"\n",
    "\n",
    "        B, seq_len, D = x.shape # seq_len is T * P\n",
    "\n",
    "        # 1. Temporal Positional Encoding (Year, Month, Day)\n",
    "        # Generate embeddings for each component\n",
    "        # 1. Temporal Positional Encoding (Year, Month, Day)\n",
    "        pe_year = self._generate_sinusoidal_encoding(years.float(), self.d_model_year, self.year_div_term_base) # (B, d_model_year)\n",
    "        pe_month = self._generate_sinusoidal_encoding(months.float(), self.d_model_month, self.month_div_term_base) # (B, d_model_month)\n",
    "        pe_day = self._generate_sinusoidal_encoding(days.float(), self.d_model_day, self.day_div_term_base) # (B, d_model_day)\n",
    "\n",
    "        # Concatenate temporal components to form the full temporal embedding for each sequence\n",
    "        # Shape: (B, d_model_year + d_model_month + d_model_day) which sums to d_model_temporal_total\n",
    "        temp_pos_batch = torch.cat([pe_year, pe_month, pe_day], dim=-1) # (B, d_model_temporal_total)\n",
    "        full_temporal_pe = temp_pos_batch.unsqueeze(1).unsqueeze(1).expand(-1, context_length, self.num_patches, -1)\n",
    "        \n",
    "        # 2. Spatial Positional Encoding (Lat/Lon)(from LatLonPositionalEncoding)\n",
    "        # spat_pos_per_patch: (P, d_model) - fixed embedding for each unique patch\n",
    "        spat_pos_per_patch = self.spatial_encoding_module().to(x.device)\n",
    "        full_spatial_pe = spat_pos_per_patch.unsqueeze(0).unsqueeze(0).expand(B, context_length, -1, -1)\n",
    "        \n",
    "        # 3. Concatenate temporal and spatial positional embeddings\n",
    "        # The result will be (B, T, P, d_model_temporal_total + d_model_spatial_total)\n",
    "        # which equals (B, T, P, d_model) if dimensions were allocated correctly.\n",
    "        combined_pe = torch.cat([full_temporal_pe, full_spatial_pe], dim=-1)\n",
    "        \n",
    "        # Flatten to (B, T*P, d_model) to match `x` after patch_embed\n",
    "        combined_pe = combined_pe.reshape(B, seq_len, D)\n",
    "\n",
    "        # Add the combined positional encoding to the input embeddings\n",
    "        x = x + combined_pe\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class LatLonPositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Generates sinusoidal positional embeddings for latitude and longitude coordinates.\n",
    "    This replaces a learnable patch embedding with a fixed, coordinate-based one.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    d_model : int\n",
    "        The dimension of the model's hidden states (embedding dimension).\n",
    "        Must be an even number as it's split between lat and lon.\n",
    "    patch_latlons : torch.Tensor\n",
    "        A tensor of shape (num_patches, 2) where the second dimension contains\n",
    "        [latitude, longitude] for each patch.\n",
    "    lat_threshold : float\n",
    "        The minimum latitude value (e.g., 40.0 for 40 degrees North) to use\n",
    "        for normalizing latitudes. Latitudes will be normalized from\n",
    "        [lat_threshold, 90.0] to [0.0, 1.0].\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, patch_latlons: torch.Tensor, lat_threshold: float):\n",
    "        super().__init__()\n",
    "        if d_model % 2 != 0:\n",
    "            raise ValueError(f\"d_model must be an even number for LatLonPositionalEncoding, got {d_model}\")\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_patches = patch_latlons.shape[0]\n",
    "        self.lat_threshold = lat_threshold\n",
    "\n",
    "        # Ensure patch_latlons is on CPU and convert to numpy for calculations\n",
    "        latlons_np = patch_latlons.cpu().numpy()\n",
    "        latitudes = latlons_np[:, 0] # (num_patches,)\n",
    "        longitudes = latlons_np[:, 1] # (num_patches,)\n",
    "\n",
    "        # Validate latitudes are within the expected range for the new normalization\n",
    "        if np.min(latitudes) < lat_threshold:\n",
    "            raise ValueError(\n",
    "                f\"Minimum latitude in patch_latlons ({np.min(latitudes):.2f}) \"\n",
    "                f\"is less than lat_threshold ({lat_threshold:.2f}). \"\n",
    "                f\"Adjust lat_threshold or ensure data is within range.\"\n",
    "            )\n",
    "        if np.max(latitudes) > 90.0:\n",
    "             # This might be okay if data goes slightly above 90 due to rounding, but warn\n",
    "             print(f\"Warning: Maximum latitude in patch_latlons ({np.max(latitudes):.2f}) \"\n",
    "                   f\"is greater than 90.0. Normalization may be affected.\")\n",
    "\n",
    "        # Normalize latitudes from [lat_threshold, 90.0] to [0.0, 1.0]\n",
    "        # Denominator: (max_val - min_val) = (90.0 - lat_threshold)\n",
    "        lat_range = 90.0 - lat_threshold\n",
    "        if lat_range <= 0: # Avoid division by zero if threshold is 90 or higher\n",
    "            raise ValueError(\"lat_threshold must be less than 90.0 for latitude normalization.\")\n",
    "        normalized_latitudes = (latitudes - lat_threshold) / lat_range\n",
    "\n",
    "        # Longitude normalization: -180 to 180 to [0, 1]\n",
    "        normalized_longitudes = (longitudes + 180) / 360.0\n",
    "\n",
    "        # Create positional encoding matrix for latitude and longitude\n",
    "        pe_lat = self._generate_sinusoidal_encoding(normalized_latitudes, d_model // 2)\n",
    "        pe_lon = self._generate_sinusoidal_encoding(normalized_longitudes, d_model // 2)\n",
    "\n",
    "        # Concatenate latitude and longitude encodings\n",
    "        self.latlon_pe = nn.Parameter(torch.cat([pe_lat, pe_lon], dim=-1), requires_grad=False)\n",
    "\n",
    "    def _generate_sinusoidal_encoding(self, positions: np.ndarray, dim: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Generates sinusoidal positional encoding for a single coordinate.\n",
    "        \"\"\"\n",
    "        position = positions[:, np.newaxis] # (num_patches, 1)\n",
    "        div_term = np.exp(np.arange(0, dim, 2) * -(np.log(10000.0) / dim)) # (dim/2,)\n",
    "        div_term = div_term[np.newaxis, :] # (1, dim/2)\n",
    "\n",
    "        pe = np.zeros((self.num_patches, dim))\n",
    "        pe[:, 0::2] = np.sin(position * div_term)\n",
    "        pe[:, 1::2] = np.cos(position * div_term)\n",
    "\n",
    "        return torch.tensor(pe, dtype=torch.float32)\n",
    "\n",
    "    def forward(self) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns the pre-calculated latitude/longitude positional embeddings.\n",
    "        \"\"\"\n",
    "        return self.latlon_pe.to(self.latlon_pe.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e3d47c-9e26-41da-9b6b-7afe0faf54ab",
   "metadata": {},
   "source": [
    "# Model Hyperparameter Constants / Defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0bd6b153-3646-4b50-b1e7-2807eac982bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Constants:\n",
    "CONTEXT_LENGTH = 7         # T: Number of historical time steps used for input\n",
    "FORECAST_HORIZON = 3       # Number of future time steps to predict (ex. 1 day for next time step)\n",
    "\n",
    "# Space Constants:\n",
    "LAT_THRESHOLD = 40\n",
    "NUM_PATCHES = 140          # P: Number of spatial patches\n",
    "NUM_FEATURES = 2           # C: Number of features per cell (ex., Freeboard, Ice Area)\n",
    "CELLS_PER_PATCH = 256      # L: Number of cells within each patch\n",
    "\n",
    "# Model Constants\n",
    "D_MODEL = 128              # d_model: Dimension of the transformer's internal representations (embedding dimension)\n",
    "N_HEAD = 8                 # nhead: Number of attention heads\n",
    "NUM_TRANSFORMER_LAYERS = 4 # num_layers: Number of TransformerEncoderLayers\n",
    "\n",
    "# Patch locations for positional embedding\n",
    "PATCH_LATLONS_TENSOR = torch.tensor(dataset.patch_latlons, dtype=torch.float32)\n",
    "\n",
    "# The input dimension for the patch embedding linear layer.\n",
    "# Each patch at a given time step has NUM_FEATURES * CELLS_PER_PATCH features.\n",
    "# This is the 'D' dimension used in the Transformer's input tensor (B, T, P, D).\n",
    "PATCH_EMBEDDING_INPUT_DIM = NUM_FEATURES * CELLS_PER_PATCH # 2 * 256 = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a530e07f-87ea-40b0-9df1-b1e053583e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "if D_MODEL % 2 != 0:\n",
    "    raise ValueError(f\"D_MODEL must be an even number\")\n",
    "\n",
    "# Ensure d_model can be split into 3 for time and 2 for spatial, and possibly a remainder\n",
    "if D_MODEL < 5: # At least 1 for year, 1 for month, 1 for day, 1 for lat, 1 for lon\n",
    "     raise ValueError(\"d_model must be at least 5 for this combined encoding setup.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59da72b-3a07-4183-a3a2-49fa953cdd1f",
   "metadata": {},
   "source": [
    "# Transformer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9d9baa0-427e-49d9-a50a-97c3d60a18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class IceForecastTransformer(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    A Transformer-based model for forecasting ice conditions based on sequences of\n",
    "    historical patch data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_patch_features_dim : int\n",
    "        The dimensionality of the feature vector for each individual patch (ex. 2 features).\n",
    "        This is the input dimension for the patch embedding layer.\n",
    "    num_patches : int\n",
    "        The total number of geographical patches that the `nCells` data was divided into.\n",
    "        (ex., 256 patches).\n",
    "    context_length : int, optional\n",
    "        The number of historical days (time steps) to use as input for the transformer.\n",
    "        Defaults to 7.\n",
    "    forecast_horizon : int, optional\n",
    "        The number of future days to predict for each patch.\n",
    "        Defaults to 1.\n",
    "    d_model : int, optional\n",
    "        The dimension of the model's hidden states (embedding dimension).\n",
    "        This is the size of the vectors that flow through the Transformer encoder.\n",
    "        Defaults to 128.\n",
    "    nhead : int, optional\n",
    "        The number of attention heads in the multi-head attention mechanism within\n",
    "        each Transformer encoder layer. Defaults to 8.\n",
    "    num_layers : int, optional\n",
    "        The number of Transformer encoder layers in the model. Defaults to 4.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    patch_embed : nn.Linear\n",
    "        Linear layer to project input patch features into the `d_model` hidden space.\n",
    "    encoder : nn.TransformerEncoder\n",
    "        The Transformer encoder module composed of `num_layers` encoder layers.\n",
    "    mlp_head : nn.Sequential\n",
    "        A multi-layer perceptron head for outputting predictions for each patch.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 input_patch_features_dim: int, # D: The flat feature dimension of a single patch (ex., 512)\n",
    "                 num_patches: int,              # P: Number of spatial patches\n",
    "                 context_length: int,           # T: Number of historical time steps\n",
    "                 forecast_horizon: int,         # Number of future time steps to predict (usually 1)\n",
    "                 d_model: int = D_MODEL,        # d_model: Transformer's embedding dimension\n",
    "                 nhead: int = N_HEAD,           # nhead: Number of attention heads\n",
    "                 num_layers: int = NUM_TRANSFORMER_LAYERS, # num_layers: Number of TransformerEncoderLayers\n",
    "                 patch_latlons: torch.Tensor = None, # for the positional encoding\n",
    "                 lat_threshold: float = 40.0,\n",
    "                 dropout: float = 0.1\n",
    "                ):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The transformer should\n",
    "        1. Accept a sequence of days (ex. 7 days of patches). \n",
    "           The context_length parameter says how many days to use for input.\n",
    "        2. Encode each patch with the transformer.\n",
    "        3. Output the patches for regression (ex. predict the 8th day).\n",
    "           The forecast_horizon parameter says how many days to use for the output prediction.\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        self.context_length = context_length\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        self.num_patches = num_patches\n",
    "        self.d_model = d_model\n",
    "        self.input_patch_features_dim = input_patch_features_dim\n",
    "   \n",
    "        print(\"Calling IceForecastTransformer __init__\")\n",
    "        print(\"context_length:\", self.context_length)\n",
    "        print(\"forecast_horizon:\", self.forecast_horizon)\n",
    "        print(\"num_patches:\", self.num_patches)\n",
    "        print(\"d_model:\", self.d_model)\n",
    "        print(\"input_patch_features_dim:\", self.input_patch_features_dim)\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        # Patch embedding layer: projects the raw patch features (512)\n",
    "        # into d_model (128) hidden space dimension\n",
    "        self.patch_embed = nn.Linear(input_patch_features_dim, d_model)\n",
    "\n",
    "        # --- Positional Encoding Layer\n",
    "        if patch_latlons is None:\n",
    "            raise ValueError(\"patch_latlons must be provided for positional encoding.\")\n",
    "\n",
    "        # Assert that num_patches matches the provided patch_latlons\n",
    "        if num_patches != patch_latlons.shape[0]:\n",
    "            raise ValueError(f\"num_patches ({num_patches}) does not match \"\n",
    "                             f\"patch_latlons.shape[0] ({patch_latlons.shape[0]})\")\n",
    "\n",
    "        self.pos_encoder = CombinedPositionalEncoder(\n",
    "            d_model=d_model,\n",
    "            patch_latlons=patch_latlons, # <--- Pass patch_latlons\n",
    "            lat_threshold=lat_threshold, # <--- Pass lat_threshold\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # --- Transformer Encoder\n",
    "        # batch_first=True means input/output tensors are (batch, sequence, features)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # --- Output MLP head: (B, P, CELLS_PER_PATCH * forecast_horizon)\n",
    "        # Make a prediction for every cell per patch\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, CELLS_PER_PATCH * forecast_horizon)\n",
    "        )\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(f\"Elapsed time: {end_time - start_time:.2f} seconds\")\n",
    "        print(\"End of __init__\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor, \n",
    "                years: torch.Tensor, months: torch.Tensor, days: torch.Tensor ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x: Tensor of shape (B, T, P, D)\n",
    "            B = Batch size\n",
    "            T = Time (context_length)\n",
    "            P = Patch count\n",
    "            D = Patch Dimension (cells per patch * feature count)\n",
    "        years, months, days: Tensors of shape (B,) containing the respective temporal components\n",
    "                             for the start of each sequence in the batch.\n",
    "        Output: Tensor of shape (batch_size, forecast_horizon, num_patches, CELLS_PER_PATCH)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initial input x shape from DataLoader / pre-processing:\n",
    "        # (B, T, P, D) i.e., (Batch_Size, Context_Length, Num_Patches, Input_Patch_Features_Dim)\n",
    "        # Example: (16, 7, 140, 512)\n",
    "        \n",
    "        B, T, P, D = x.shape\n",
    "\n",
    "        # Flatten time and patches for the Transformer Encoder:\n",
    "        # Each (Time, Patch) combination becomes a single token in the sequence.\n",
    "        # Output shape: (B, T * P, D)\n",
    "        # Example: (16, 7 * 140 = 980, 512)\n",
    "        \n",
    "        # Flatten time and patches for the Transformer Encoder: (B, T * P, D)\n",
    "        # This treats each patch at each time step as a distinct token\n",
    "        x = x.view(B, T * P, D)\n",
    "\n",
    "        # Project patch features to the transformer's d_model dimension\n",
    "        x = self.patch_embed(x)  # Output: (B, T * P, d_model) ex., (16, 980, 128)\n",
    "\n",
    "        # Apply positional encoding\n",
    "        x = self.pos_encoder(x, years, months, days, self.context_length)\n",
    "        \n",
    "        # Apply transformer encoder layers\n",
    "        x = self.encoder(x)      # Output: (B, T * P, d_model) ex., (16, 980, 128)\n",
    "\n",
    "        # Reshape back to separate time and patches: (B, T, P, d_model) ex., (16, 7, 140, 128)\n",
    "        x = x.view(B, T, P, self.d_model) \n",
    "\n",
    "        # Mean pooling over the time (context_length) dimension for each patch.\n",
    "        # This aggregates information from all historical time steps for each patch's final prediction.        \n",
    "        x = x.mean(dim=1)  # Output: (B, P, d_model) ex., (16, 140, 128)\n",
    "\n",
    "        # TODO: SOMEHOW SAVE ATTENTION TO MAP LATER\n",
    "\n",
    "        # Apply MLP head to predict values for each cell in each patch\n",
    "        # The MLP head outputs (B, P, CELLS_PER_PATCH * forecast_horizon)\n",
    "        x = self.mlp_head(x) # ex. (16, 140, 256 * 3) = (16, 140, 768)\n",
    "\n",
    "        # Reshape the output to (B, forecast_horizon, P, CELLS_PER_PATCH)\n",
    "        # Explicitly reshape the last dimension to seperate the forecast horizon out\n",
    "        x = x.view(B, P, self.forecast_horizon, CELLS_PER_PATCH) # Reshape into forecast_horizon and CELLS_PER_PATCH\n",
    "        x = x.permute(0, 2, 1, 3) # Permute to (B, forecast_horizon, P, CELLS_PER_PATCH)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e200db32-3fbb-4f8f-b841-bbcdc9117c11",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7383efb0-3e8d-468d-bf66-0bb91f943ba8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling IceForecastTransformer __init__\n",
      "context_length: 7\n",
      "forecast_horizon: 3\n",
      "num_patches: 140\n",
      "d_model: 128\n",
      "input_patch_features_dim: 512\n",
      "Elapsed time: 0.01 seconds\n",
      "End of __init__\n",
      "\n",
      "--- Model Architecture ---\n",
      "IceForecastTransformer(\n",
      "  (patch_embed): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (pos_encoder): CombinedPositionalEncoder(\n",
      "    (spatial_encoding_module): LatLonPositionalEncoding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder_layer): TransformerEncoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
      "    (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
      "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_head): Sequential(\n",
      "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=128, out_features=768, bias=True)\n",
      "  )\n",
      ")\n",
      "--------------------------\n",
      "\n",
      "Epoch 1/10 - Train Loss: 0.5395\n",
      "Validation Loss: 0.3797\n",
      "Epoch 2/10 - Train Loss: 0.3810\n",
      "Validation Loss: 0.2992\n",
      "Epoch 3/10 - Train Loss: 0.3036\n",
      "Validation Loss: 0.2496\n",
      "Epoch 4/10 - Train Loss: 0.2552\n",
      "Validation Loss: 0.2164\n",
      "Epoch 5/10 - Train Loss: 0.2184\n",
      "Validation Loss: 0.1847\n",
      "Epoch 6/10 - Train Loss: 0.1900\n",
      "Validation Loss: 0.1571\n",
      "Epoch 7/10 - Train Loss: 0.1628\n",
      "Validation Loss: 0.1302\n",
      "Epoch 8/10 - Train Loss: 0.1407\n",
      "Validation Loss: 0.1096\n",
      "Epoch 9/10 - Train Loss: 0.1228\n",
      "Validation Loss: 0.0933\n",
      "Epoch 10/10 - Train Loss: 0.1095\n",
      "Validation Loss: 0.0818\n",
      "===============================================\n",
      "Elapsed time for TRAINING: 48.78 seconds\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import logging\n",
    "\n",
    "# Set level to logging.INFO to see the statements\n",
    "logging.basicConfig(filename='IceForecastTransformerInstance.log', filemode='w', level=logging.INFO)\n",
    "\n",
    "model = IceForecastTransformer(\n",
    "    input_patch_features_dim=PATCH_EMBEDDING_INPUT_DIM,\n",
    "    num_patches=NUM_PATCHES,\n",
    "    context_length=CONTEXT_LENGTH,\n",
    "    forecast_horizon=FORECAST_HORIZON,\n",
    "    d_model=D_MODEL,\n",
    "    nhead=N_HEAD,\n",
    "    num_layers=NUM_TRANSFORMER_LAYERS,\n",
    "    patch_latlons=PATCH_LATLONS_TENSOR, # <--- Pass the patch_latlons tensor for positional embedding\n",
    "    lat_threshold=LAT_THRESHOLD    # <--- Pass the latitude threshold for positional embedding\n",
    ").to(device)\n",
    "\n",
    "print(\"\\n--- Model Architecture ---\")\n",
    "print(model)\n",
    "print(\"--------------------------\\n\")\n",
    "\n",
    "logging.info(\"\\n--- Model Architecture ---\")\n",
    "logging.info(str(model)) # Log the full model structure\n",
    "logging.info(f\"Total model parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
    "logging.info(\"--------------------------\\n\")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "#num_epochs = 100\n",
    "num_epochs = 10\n",
    "\n",
    "start_time = time.time()\n",
    "logging.info(\"===============================\")\n",
    "logging.info(\"       STARTING EPOCHS       \")\n",
    "logging.info(\"===============================\")\n",
    "logging.info(f\"Number of epochs: {num_epochs}\")\n",
    "logging.info(f\"Learning Rate: {optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    # Unpack the train_loader\n",
    "    for batch_idx, (input_tensor, target_tensor,\n",
    "                    start_idx, end_idx, target_start, target_end,\n",
    "                    years, months, days) in enumerate(train_loader):\n",
    "\n",
    "        # Move input and target to the device\n",
    "        # x: (B, context_length, num_patches, num_features, patch_size)\n",
    "        # y: (B, forecast_horizon, num_patches, CELLS_PER_PATCH)\n",
    "        x = input_tensor.to(device)  # Shape: (B, T, P, C, L)\n",
    "        y = target_tensor.to(device)  # Shape: (B, forecast_horizon, P, L)\n",
    "        years = years.to(device)\n",
    "        months = months.to(device)\n",
    "        days = days.to(device)\n",
    "        \n",
    "        # Reshape x for transformer input\n",
    "        B, T, P, C, L = x.shape\n",
    "        x_reshaped_for_transformer_D = x.view(B, T, P, C * L)\n",
    "        \n",
    "        # Run through transformer - y_pred is (B, forecast_horizon, num_patches, CELLS_PER_PATCH) \n",
    "        # Pass the input tensor and the temporal components\n",
    "        y_pred = model(x_reshaped_for_transformer_D, years, months, days)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(y_pred, y) # y_pred and y should now have identical shapes (B, FH, P, CPC)\n",
    "     \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    logging.info(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}\")\n",
    "    \n",
    "    # --- Validation loop ---\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Unpack the validation loader\n",
    "        for batch_idx_val, (x_val, y_val, \n",
    "                            start_idx_val, end_idx_val, target_start_val, target_end_val,\n",
    "                            years_val, months_val, days_val) in enumerate(val_loader): \n",
    "\n",
    "            # Move to GPU if available\n",
    "            x_val = x_val.to(device)\n",
    "            y_val = y_val.to(device)\n",
    "            years_val = years_val.to(device)\n",
    "            months_val = months_val.to(device)\n",
    "            days_val = days_val.to(device)\n",
    "\n",
    "            # Extract dimensions from x_val for reshaping\n",
    "            # x_val before reshaping: (B_val, T_val, P_val, C_val, L_val)\n",
    "            B_val, T_val, P_val, C_val, L_val = x_val.shape\n",
    "            \n",
    "            # Reshape x_val for transformer input\n",
    "            x_val_reshaped_for_transformer_input = x_val.view(B_val, T_val, P_val, C_val * L_val)\n",
    "\n",
    "            # Model output is (B, forecast_horizon, P, CELLS_PER_PATCH)\n",
    "            y_val_pred = model(x_val_reshaped_for_transformer_input, years_val, months_val, days_val)\n",
    "\n",
    "            # Compute validation loss (y_val_pred and y_val should have identical shapes)\n",
    "            val_loss += criterion(y_val_pred, y_val).item() # y_val is (B, forecast_horizon, P, L)\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    logging.info(f\"Epoch {epoch+1}/{num_epochs} - Validation Loss: {avg_val_loss:.4f}\")\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}\") # Keep print for immediate console feedback\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "logging.info(\"===============================================\")\n",
    "logging.info(f\"Elapsed time for TRAINING: {elapsed_time:.2f} seconds\")\n",
    "logging.info(\"===============================================\")\n",
    "print(\"===============================================\")\n",
    "print(f\"Elapsed time for TRAINING: {elapsed_time:.2f} seconds\")\n",
    "print(\"===============================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a56564-d7f8-4060-bfa9-8edb3fce9d83",
   "metadata": {},
   "source": [
    "TODO: Add Positional Encoding to represent time steps.\n",
    "\n",
    "TODO OPTION: Try temporal attention only (ex., Informer, Time Series Transformer).\n",
    "\n",
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ecdd478-4bc1-4a3f-b91d-b40f03db7d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model number\n",
    "model_version = \"practice_2_pos_enc\"\n",
    "\n",
    "# Define the path where to save or load the model\n",
    "PATH = f\"sea_ice_concentration_model_{model_version}.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d61b69c0-01b8-491a-b71b-79ac6a7798d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model\n"
     ]
    }
   ],
   "source": [
    "# Comment this out if you don't need to save the model\n",
    "# Save the model's state_dict\n",
    "torch.save(model.state_dict(), PATH)\n",
    "print(\"Saved model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f278114f-96bb-4bbc-8e7f-f87c52e2a946",
   "metadata": {},
   "source": [
    "# Re-Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca0dc4b5-7cca-4a6d-99fd-6754ca833879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling IceForecastTransformer __init__\n",
      "context_length: 7\n",
      "forecast_horizon: 3\n",
      "num_patches: 140\n",
      "d_model: 128\n",
      "input_patch_features_dim: 512\n",
      "Elapsed time: 0.01 seconds\n",
      "End of __init__\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise ValueError(\"There is a problem with Torch not recognizing the GPUs\")\n",
    "\n",
    "# Instantiate the model (must have the same architecture as when it was saved)\n",
    "# Create an identical instance of the original __init__ parameters\n",
    "# Make sure global constants (like D_MODEL, N_HEAD, etc.) are consistent.\n",
    "loaded_model = IceForecastTransformer(\n",
    "    input_patch_features_dim=PATCH_EMBEDDING_INPUT_DIM,\n",
    "    num_patches=NUM_PATCHES,\n",
    "    context_length=CONTEXT_LENGTH,\n",
    "    forecast_horizon=FORECAST_HORIZON,\n",
    "    d_model=D_MODEL,\n",
    "    nhead=N_HEAD,\n",
    "    num_layers=NUM_TRANSFORMER_LAYERS,\n",
    "    patch_latlons=PATCH_LATLONS_TENSOR, # <--- Pass the patch_latlons tensor\n",
    "    lat_threshold=LAT_THRESHOLD    # <--- Pass the latitude threshold\n",
    ")\n",
    "\n",
    "# Load the saved state_dict (weights_only=True helps ensure safety of pickle files)\n",
    "loaded_model.load_state_dict(torch.load(PATH, weights_only=True))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "loaded_model.eval()\n",
    "\n",
    "# Move the model to the appropriate device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loaded_model.to(device)\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661e362e-fc7b-4692-93aa-96dc68546d91",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e630a7cf-9771-4b4d-b266-459305b95876",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# Accumulators for errors\n",
    "all_abs_errors = [] # To store absolute errors for each cell in each patch\n",
    "all_mse_errors = [] # To store MSE for each cell in each patch\n",
    "\n",
    "# Accumulators for histogram data\n",
    "all_predicted_values_flat = []\n",
    "all_actual_values_flat = []\n",
    "\n",
    "print(\"\\nStarting evaluation and metric calculation...\")\n",
    "print(\"==================\")\n",
    "print(f\"DEBUG: Batch Size: {BATCH_SIZE} Days\")\n",
    "print(f\"DEBUG: Context Length: {CONTEXT_LENGTH} Days\")\n",
    "print(f\"DEBUG: Forecast Horizon: {FORECAST_HORIZON} Days\")\n",
    "print(f\"DEBUG: Number of batches in test_loader (with drop_last=True): {len(test_loader)} Batches\")\n",
    "print(\"==================\")\n",
    "print(f\"DEBUG: len(test_set): {len(test_set)} Days\")\n",
    "print(f\"DEBUG: len(dataset) for splitting: {len(dataset)} Days\") # Should be 356\n",
    "print(f\"DEBUG: train_end: {train_end}\")\n",
    "print(f\"DEBUG: val_end: {val_end}\") # Should be 302\n",
    "print(f\"DEBUG: range for test_set: {range(val_end, total_days)}\") # Should be range(302, 356)\n",
    "print(\"==================\")\n",
    "\n",
    "# Iterate over the test_loader\n",
    "for i, (sample_x, sample_y, \n",
    "        start_idx, end_idx, target_start, target_end, \n",
    "        years, months, days) in enumerate(test_loader):\n",
    "    print(f\"Processing batch {i+1}/{len(test_loader)}\")\n",
    "\n",
    "    # Move to device and apply initial reshape as done in training\n",
    "    sample_x = sample_x.to(device)\n",
    "    sample_y = sample_y.to(device) # Actual target values\n",
    "    years = years.to(device)\n",
    "    months = months.to(device)\n",
    "    days = days.to(device)\n",
    "    \n",
    "    # Initial reshape of x for the Transformer model\n",
    "    B_sample, T_sample, P_sample, C_sample, L_sample = sample_x.shape\n",
    "    sample_x_reshaped = sample_x.view(B_sample, T_sample, P_sample, C_sample * L_sample)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad(): # Essential for inference to disable gradient calculations\n",
    "        predicted_y_patches = loaded_model(sample_x_reshaped, years, months, days)\n",
    "\n",
    "    # Ensure predicted_y_patches and sample_y have the same shape for comparison\n",
    "    # Expected shape: (B, forecast_horizon, NUM_PATCHES, CELLS_PER_PATCH)\n",
    "    if predicted_y_patches.shape != sample_y.shape:\n",
    "        print(f\"Shape mismatch: Predicted {predicted_y_patches.shape}, Actual {sample_y.shape}\")\n",
    "        continue # Skip this batch if shapes are incompatible\n",
    "\n",
    "    # Calculate errors for each cell in each patch, across the forecast horizon and batch\n",
    "    # The errors will implicitly be averaged over the batch when we take the mean later\n",
    "    diff = predicted_y_patches - sample_y\n",
    "    abs_error_batch = torch.abs(diff)\n",
    "    mse_error_batch = diff ** 2\n",
    "\n",
    "    # Accumulate errors (move to CPU for storage if memory is a concern)\n",
    "    all_abs_errors.append(abs_error_batch.cpu())\n",
    "    all_mse_errors.append(mse_error_batch.cpu())\n",
    "\n",
    "    # Collect data for histograms (flatten all values)\n",
    "    all_predicted_values_flat.append(predicted_y_patches.cpu().numpy().flatten())\n",
    "    all_actual_values_flat.append(sample_y.cpu().numpy().flatten())\n",
    "\n",
    "# Concatenate all accumulated tensors\n",
    "if all_abs_errors and all_mse_errors:\n",
    "    combined_abs_errors = torch.cat(all_abs_errors, dim=0) # Shape: (Total_Samples, FH, P, CPC)\n",
    "    combined_mse_errors = torch.cat(all_mse_errors, dim=0) # Shape: (Total_Samples, FH, P, CPC)\n",
    "\n",
    "    # Calculate average MSE and Absolute Error for each cell in each patch\n",
    "    # Average over batch size and forecast horizon\n",
    "    # Resulting shape: (NUM_PATCHES, CELLS_PER_PATCH)\n",
    "    mean_abs_error_per_cell_patch = combined_abs_errors.mean(dim=(0, 1)) # Average over batch and forecast horizon\n",
    "    mean_mse_per_cell_patch = combined_mse_errors.mean(dim=(0, 1)) # Average over batch and forecast horizon\n",
    "\n",
    "    print(\"\\n--- Error Metrics (Averaged per Cell per Patch) ---\")\n",
    "    print(f\"Mean Absolute Error (shape {mean_abs_error_per_cell_patch.shape}):\")\n",
    "    # print(mean_abs_error_per_cell_patch) # Uncomment to see the full tensor\n",
    "    print(f\"Overall Mean Absolute Error:            {mean_abs_error_per_cell_patch.mean().item():.4f}\")\n",
    "\n",
    "    print(f\"\\nMean Squared Error (shape {mean_mse_per_cell_patch.shape}):\")\n",
    "    # print(mean_mse_per_cell_patch) # Uncomment to see the full tensor\n",
    "\n",
    "    mse = mean_mse_per_cell_patch.mean().item()\n",
    "    print(f\"Overall Mean Squared Error:             {mse:.4f}\")\n",
    "\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f\"Overall Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No data processed for error metrics. Check test_loader and data availability.\")\n",
    "\n",
    "# --- Histogram and Jensen-Shannon Distance ---\n",
    "\n",
    "# Concatenate all flattened values\n",
    "if all_predicted_values_flat and all_actual_values_flat:\n",
    "    final_predicted_values = np.concatenate(all_predicted_values_flat)\n",
    "    final_actual_values = np.concatenate(all_actual_values_flat)\n",
    "\n",
    "    print(f\"\\nTotal predicted values collected: {len(final_predicted_values)}\")\n",
    "    print(f\"Total actual values collected: {len(final_actual_values)}\")\n",
    "\n",
    "    # Define bins for the histogram (e.g., for ice concentration between 0 and 1)\n",
    "    # Adjust bins based on the expected range of your data\n",
    "    bins = np.linspace(0, 1, 51) # 50 bins from 0 to 1\n",
    "\n",
    "    # Compute histograms\n",
    "    hist_predicted, _ = np.histogram(final_predicted_values, bins=bins, density=True)\n",
    "    hist_actual, _ = np.histogram(final_actual_values, bins=bins, density=True)\n",
    "\n",
    "    # Normalize histograms to sum to 1 (they are already density=True, but re-normalize for safety)\n",
    "    hist_predicted = hist_predicted / hist_predicted.sum()\n",
    "    hist_actual = hist_actual / hist_actual.sum()\n",
    "\n",
    "    # Jensen-Shannon Distance function\n",
    "    def jensen_shannon_distance(p, q):\n",
    "        \"\"\"Calculates the Jensen-Shannon distance between two probability distributions.\"\"\"\n",
    "        # Ensure distributions sum to 1\n",
    "        p = p / p.sum()\n",
    "        q = q / q.sum()\n",
    "\n",
    "        m = 0.5 * (p + q)\n",
    "        # Add a small epsilon to avoid log(0)\n",
    "        epsilon = 1e-10\n",
    "        jsd = 0.5 * (entropy(p + epsilon, m + epsilon) + entropy(q + epsilon, m + epsilon))\n",
    "        return np.sqrt(jsd) # JSD is the square root of JS divergence\n",
    "\n",
    "    # Calculate Jensen-Shannon Distance\n",
    "    jsd = jensen_shannon_distance(hist_actual, hist_predicted)\n",
    "    print(f\"\\nJensen-Shannon Distance between actual and predicted histograms: {jsd:.4f}\")\n",
    "\n",
    "    # Plotting Histograms\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(final_actual_values, bins=bins, alpha=0.7, label='Actual Data', color='skyblue', density=True)\n",
    "    plt.hist(final_predicted_values, bins=bins, alpha=0.7, label='Predicted Data', color='salmon', density=True)\n",
    "    plt.title('Distribution of Actual vs. Predicted Ice Concentration Values')\n",
    "    plt.xlabel('Ice Concentration Value')\n",
    "    plt.ylabel('Probability Density')\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.savefig(f\"SIE_Distribution_Actual_vs_Predicted_model_{model_version}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # When reading the histograms, look for overlap:\n",
    "    # High Overlap: predictions are close to actual values. Decent model.\n",
    "    # Low Overlap: predictions differ from actual values, issues with the model. \n",
    "\n",
    "else:\n",
    "    print(\"No data collected for histogram analysis. Check test_loader and data availability.\")\n",
    "\n",
    "print(\"\\nEvaluation complete.\")\n",
    "\n",
    "with open(f'{model_version}_Metrics.txt', 'w') as f:\n",
    "    f.write(captured_output.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e4e80fa-e716-435f-8d94-64892ec92677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "See Metrics.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"See Metrics.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681c7955-7de9-4ac1-ae71-ef1f7bedd950",
   "metadata": {},
   "source": [
    "# Make a Single Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e76ed2c4-bee4-4fd0-81b6-79a3e79ded48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sample_x torch.Size([16, 7, 140, 2, 256])\n",
      "Shape of sample_y torch.Size([16, 3, 140, 256])\n",
      "Fetched sample_x start index tensor([302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315,\n",
      "        316, 317]): Time=['0010-10-30T00:00:00' '0010-10-31T00:00:00' '0010-11-01T00:00:00'\n",
      " '0010-11-02T00:00:00' '0010-11-03T00:00:00' '0010-11-04T00:00:00'\n",
      " '0010-11-05T00:00:00' '0010-11-06T00:00:00' '0010-11-07T00:00:00'\n",
      " '0010-11-08T00:00:00' '0010-11-09T00:00:00' '0010-11-10T00:00:00'\n",
      " '0010-11-11T00:00:00' '0010-11-12T00:00:00' '0010-11-13T00:00:00'\n",
      " '0010-11-14T00:00:00']\n",
      "Fetched sample_x end   index tensor([309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322,\n",
      "        323, 324]):   Time=['0010-11-06T00:00:00' '0010-11-07T00:00:00' '0010-11-08T00:00:00'\n",
      " '0010-11-09T00:00:00' '0010-11-10T00:00:00' '0010-11-11T00:00:00'\n",
      " '0010-11-12T00:00:00' '0010-11-13T00:00:00' '0010-11-14T00:00:00'\n",
      " '0010-11-15T00:00:00' '0010-11-16T00:00:00' '0010-11-17T00:00:00'\n",
      " '0010-11-18T00:00:00' '0010-11-19T00:00:00' '0010-11-20T00:00:00'\n",
      " '0010-11-21T00:00:00']\n",
      "Fetched sample_y (target) start index tensor([312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327]): Time=['0010-11-09T00:00:00' '0010-11-10T00:00:00' '0010-11-11T00:00:00'\n",
      " '0010-11-12T00:00:00' '0010-11-13T00:00:00' '0010-11-14T00:00:00'\n",
      " '0010-11-15T00:00:00' '0010-11-16T00:00:00' '0010-11-17T00:00:00'\n",
      " '0010-11-18T00:00:00' '0010-11-19T00:00:00' '0010-11-20T00:00:00'\n",
      " '0010-11-21T00:00:00' '0010-11-22T00:00:00' '0010-11-23T00:00:00'\n",
      " '0010-11-24T00:00:00']\n",
      "Fetched sample_y (target) end   index tensor([312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327]): Time=['0010-11-09T00:00:00' '0010-11-10T00:00:00' '0010-11-11T00:00:00'\n",
      " '0010-11-12T00:00:00' '0010-11-13T00:00:00' '0010-11-14T00:00:00'\n",
      " '0010-11-15T00:00:00' '0010-11-16T00:00:00' '0010-11-17T00:00:00'\n",
      " '0010-11-18T00:00:00' '0010-11-19T00:00:00' '0010-11-20T00:00:00'\n",
      " '0010-11-21T00:00:00' '0010-11-22T00:00:00' '0010-11-23T00:00:00'\n",
      " '0010-11-24T00:00:00']\n",
      "Sample x for inference shape (reshaped): torch.Size([16, 7, 140, 512])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument tensors in method wrapper_CUDA_cat)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Perform inference\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(): \u001b[38;5;66;03m# Essential for inference to disable gradient calculations\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     predicted_y_patches \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_x_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myears\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted y patches shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_y_patches\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected shape: (B, forecast_horizon, NUM_PATCHES, CELLS_PER_PATCH) ex., (16, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloaded_model\u001b[38;5;241m.\u001b[39mforecast_horizon\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, 140, 256)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/sic_sie_env_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/sic_sie_env_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[41], line 154\u001b[0m, in \u001b[0;36mIceForecastTransformer.forward\u001b[0;34m(self, x, years, months, days)\u001b[0m\n\u001b[1;32m    151\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_embed(x)  \u001b[38;5;66;03m# Output: (B, T * P, d_model) ex., (16, 980, 128)\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# Apply positional encoding\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myears\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# Apply transformer encoder layers\u001b[39;00m\n\u001b[1;32m    157\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)      \u001b[38;5;66;03m# Output: (B, T * P, d_model) ex., (16, 980, 128)\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/sic_sie_env_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/sic_sie_env_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[38], line 140\u001b[0m, in \u001b[0;36mCombinedPositionalEncoder.forward\u001b[0;34m(self, x, years, months, days, context_length)\u001b[0m\n\u001b[1;32m    135\u001b[0m full_spatial_pe \u001b[38;5;241m=\u001b[39m spat_pos_per_patch\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(B, context_length, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# 3. Concatenate temporal and spatial positional embeddings\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# The result will be (B, T, P, d_model_temporal_total + d_model_spatial_total)\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# which equals (B, T, P, d_model) if dimensions were allocated correctly.\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m combined_pe \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfull_temporal_pe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_spatial_pe\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Flatten to (B, T*P, d_model) to match `x` after patch_embed\u001b[39;00m\n\u001b[1;32m    143\u001b[0m combined_pe \u001b[38;5;241m=\u001b[39m combined_pe\u001b[38;5;241m.\u001b[39mreshape(B, seq_len, D)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument tensors in method wrapper_CUDA_cat)"
     ]
    }
   ],
   "source": [
    "# Turn off the logging for this part\n",
    "# https://docs.python.org/3/library/logging.html#logrecord-attributes\n",
    "logging.disable(level=logging.INFO)\n",
    "\n",
    "# Load one batch\n",
    "data_iter = iter(test_loader)\n",
    "sample_x, sample_y, start_idx, end_idx, target_start, target_end, years, months, days = next(data_iter)\n",
    "\n",
    "print(f\"Shape of sample_x {sample_x.shape}\")\n",
    "print(f\"Shape of sample_y {sample_y.shape}\")   \n",
    "\n",
    "print(f\"Fetched sample_x start index {start_idx}: Time={dataset.times[start_idx]}\")\n",
    "print(f\"Fetched sample_x end   index {end_idx}:   Time={dataset.times[end_idx]}\")\n",
    "\n",
    "print(f\"Fetched sample_y (target) start index {target_end}: Time={dataset.times[target_end]}\")\n",
    "print(f\"Fetched sample_y (target) end   index {target_end}: Time={dataset.times[target_end]}\")\n",
    "\n",
    "# Move to device and apply initial reshape as done in training\n",
    "sample_x = sample_x.to(device)\n",
    "sample_y = sample_y.to(device) # Keep sample_y for actual comparison\n",
    "\n",
    "# Initial reshape of x for the Transformer model\n",
    "B_sample, T_sample, P_sample, C_sample, L_sample = sample_x.shape\n",
    "sample_x_reshaped = sample_x.view(B_sample, T_sample, P_sample, C_sample * L_sample)\n",
    "\n",
    "print(f\"Sample x for inference shape (reshaped): {sample_x_reshaped.shape}\")\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad(): # Essential for inference to disable gradient calculations\n",
    "    predicted_y_patches = loaded_model(sample_x_reshaped, years, months, days)\n",
    "\n",
    "print(f\"Predicted y patches shape: {predicted_y_patches.shape}\")\n",
    "print(f\"Expected shape: (B, forecast_horizon, NUM_PATCHES, CELLS_PER_PATCH) ex., (16, {loaded_model.forecast_horizon}, 140, 256)\")\n",
    "                 \n",
    "# Option 1: Select a specific day from the forecast horizon (ex., the first day)\n",
    "# This is the shape (B, NUM_PATCHES, CELLS_PER_PATCH) for that specific day.\n",
    "predicted_for_day_0 = predicted_y_patches[:, 0, :, :].cpu()\n",
    "print(f\"Predicted ice area for Day 0 (specific day) shape: {predicted_for_day_0.shape}\")\n",
    "\n",
    "# Ensure sample_y has the same structure\n",
    "actual_for_day_0 = sample_y[:, 0, :, :].cpu()\n",
    "print(f\"Actual ice area for Day 0 (specific day) shape: {actual_for_day_0.shape}\")\n",
    "\n",
    "# Save predictions so that I can use cartopy by switching kernels for the next jupyter cell\n",
    "np.save(f'ice_area_patches_predicted_model_{model_version}_day0.npy', predicted_for_day_0)\n",
    "np.save(f'ice_area_patches_actual_model_{model_version}_day0.npy', actual_for_day_0)\n",
    "\n",
    "# Option 2: Iterate through all forecast days\n",
    "all_predicted_ice_areas = []\n",
    "all_actual_ice_areas = []\n",
    "\n",
    "for day_idx in range(loaded_model.forecast_horizon):\n",
    "    predicted_day = predicted_y_patches[:, day_idx, :, :].cpu()\n",
    "    all_predicted_ice_areas.append(predicted_day)\n",
    "\n",
    "    actual_day = sample_y[:, day_idx, :, :].cpu()\n",
    "    all_actual_ice_areas.append(actual_day)\n",
    "\n",
    "    print(f\"Processing forecast day {day_idx}: Predicted shape {predicted_day.shape}, Actual shape {actual_day.shape}\")\n",
    "\n",
    "    # Save each day's prediction/actual data if needed\n",
    "    # np.save(f'ice_area_patches_predicted_day{day_idx}.npy', predicted_day)\n",
    "    # np.save(f'ice_area_patches_actual_day{day_idx}.npy', actual_day)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99dcfa7-f75c-4e21-9d29-c2fb3f7615ed",
   "metadata": {},
   "source": [
    "# Recover nCells from Patches for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "11de318f-3166-464d-b8e0-c79abe06766b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cartopy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m########################################\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# SWAP KERNELS IN THE JUPYTER NOTEBOOK #\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m########################################\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mMAP_ANIMATION_GENERATION\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmap_gen_utility_functions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mNC_FILE_PROCESSING\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnc_utility_functions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mNC_FILE_PROCESSING\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatchify_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/pscratch/sd/b/brelypo/Predicting_SIC_SIE/MAP_ANIMATION_GENERATION/map_gen_utility_functions.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_cmap\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Cartopy for map features, like land and ocean\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcartopy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcrs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mccrs\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcartopy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcfeature\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mMAP_ANIMATION_GENERATION\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmap_label_utility_functions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cartopy'"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# SWAP KERNELS IN THE JUPYTER NOTEBOOK #\n",
    "########################################\n",
    "\n",
    "from MAP_ANIMATION_GENERATION.map_gen_utility_functions import *\n",
    "from NC_FILE_PROCESSING.nc_utility_functions import *\n",
    "from NC_FILE_PROCESSING.patchify_utils import *\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "LAT_THRESHOLD = 40\n",
    "\n",
    "predicted_ice_area_patches = np.load(f'ice_area_patches_predicted_model_{model_version}_day0.npy')\n",
    "actual_y_ice_area_patches = np.load(f'ice_area_patches_actual_model_{model_version}_day0.npy')\n",
    "\n",
    "NUM_PATCHES = len(predicted_ice_area_patches[0])\n",
    "print(\"NUM_PATCHES is\", NUM_PATCHES)\n",
    "\n",
    "latCell, lonCell = load_mesh(perlmutterpathMesh)\n",
    "TOTAL_GRID_CELLS = len(lonCell) \n",
    "cell_mask = latCell >= LAT_THRESHOLD\n",
    "\n",
    "# Extract Freeboard (index 0) and Ice Area (index 1) for predicted and actual\n",
    "# Predicted output is (B, 1, NUM_PATCHES, CELLS_PER_PATCH)\n",
    "# Assuming the model predicts ice area, which is the second feature (index 1)\n",
    "# if the output of the model aligns with the order of features *within* the original patch_dim.\n",
    "\n",
    "# Load the original patch-to-cell mapping\n",
    "# indices_per_patch_id = [\n",
    "#     [idx_cell_0_0, ..., idx_cell_0_255],\n",
    "#     [idx_cell_1_0, ..., idx_cell_1_255],\n",
    "#     ...\n",
    "# ]\n",
    "\n",
    "full_nCells_patch_ids, indices_per_patch_id, patch_latlons = patchify_by_latlon_spillover(\n",
    "            latCell, lonCell, k=256, max_patches=140, lat_threshold=LAT_THRESHOLD)\n",
    "\n",
    "# Select one sample from the batch for visualization (ex., the first one)\n",
    "# Output is (NUM_PATCHES, CELLS_PER_PATCH) for this single sample\n",
    "sample_predicted_cells_per_patch = predicted_ice_area_patches[2] # First item in batch\n",
    "sample_actual_cells_per_patch = predicted_ice_area_patches[2] # First item in batch\n",
    "\n",
    "# Initialize empty arrays for the full grid (nCells)\n",
    "recovered_predicted_grid = np.full(TOTAL_GRID_CELLS, np.nan)\n",
    "recovered_actual_grid = np.full(TOTAL_GRID_CELLS, np.nan)\n",
    "\n",
    "# Populate the full grid using the patch data and mapping\n",
    "for patch_idx in range(NUM_PATCHES):\n",
    "    cell_indices_in_patch = indices_per_patch_id[patch_idx]\n",
    "    \n",
    "    # For predicted values\n",
    "    recovered_predicted_grid[cell_indices_in_patch] = sample_predicted_cells_per_patch[patch_idx]\n",
    "    nan_mask = np.isnan(recovered_predicted_grid)\n",
    "    nan_count = np.sum(nan_mask)\n",
    "\n",
    "    # For actual values\n",
    "    recovered_actual_grid[cell_indices_in_patch] = sample_actual_cells_per_patch[patch_idx]\n",
    "\n",
    "print(f\"Recovered predicted grid shape: {recovered_predicted_grid.shape}\")\n",
    "print(f\"Recovered actual grid shape: {recovered_actual_grid.shape}\")\n",
    "\n",
    "fig, northMap = generate_axes_north_pole()\n",
    "generate_map_north_pole(fig, northMap, latCell, lonCell, recovered_predicted_grid, f\"model {model_version} ice area recovered\")\n",
    "\n",
    "fig, northMap = generate_axes_north_pole()\n",
    "generate_map_north_pole(fig, northMap, latCell, lonCell, recovered_actual_grid, f\"model {model_version} ice area actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbabb906-c95f-445f-a9b6-2e02d2f180e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
