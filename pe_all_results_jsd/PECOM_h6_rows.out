Renamed job to: PECOM_h6_rows
Patchify strategy: rows
Forecast horizon: 6
Xarray version 2025.6.1
Zarr version 2.18.3
Numpy version 2.2.6
PyTorch version 2.5.1
Total nCells:        465044
Mask size:           53973
cells_per_patch:     256
n_patches:           210
Model Version: peCOM_Mfd_nF_D128_B16_lt40_P210_L256_T12_Fh6_e40_ROW
Dataset Name: Monthly_fd_nF_data.zarr
System Version: 3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:45:41) [GCC 13.3.0]
Pandas version 2.3.1
Matplotlib version 3.10.5
Seaborn version 0.13.2
Number of GPUs: 4
Processor Name: x86_64
Physical Cores: 64
Logical Cores: 128
Current CPU Frequency: 2709.19 MHz
Min CPU Frequency: 1500.00 MHz
Max CPU Frequency: 2450.00 MHz
Total CPU Usage: 0.3%
===== Making the Dataset Class: TRIAL_RUN MODE IS False ===== 
<xarray.Dataset> Size: 922MB
Dimensions:         (nCells_full: 465044, time: 2100, nCells_masked: 53973)
Coordinates:
  * nCells_full     (nCells_full) int64 4MB 0 1 2 3 ... 465041 465042 465043
  * nCells_masked   (nCells_masked) int64 432kB 0 1 2 3 ... 53970 53971 53972
  * time            (time) datetime64[ns] 17kB 1850-01-01T00:30:00 ... 2024-1...
Data variables:
    cell_mask       (nCells_full) bool 465kB dask.array<chunksize=(232522,), meta=np.ndarray>
    freeboard       (time, nCells_masked) float32 453MB dask.array<chunksize=(132, 3374), meta=np.ndarray>
    full_to_masked  <U1337572 5MB ...
    ice_area        (time, nCells_masked) float32 453MB dask.array<chunksize=(132, 3374), meta=np.ndarray>
    masked_to_full  <U1337572 5MB ...
    num_raw_files   int64 8B ...
    times           (time) datetime64[ns] 17kB dask.array<chunksize=(2100,), meta=np.ndarray>
processed_ds['times'].values.shape: (2100,)  # Expected: (2100,)
Type of self.times: <class 'numpy.ndarray'>
Data type of elements in self.times: datetime64[ns]
1850-01-01T00:30:00.000000000
processed_ds['ice_area'].load().values.shape: (2100, 53973)  # Expected: (2100, 53973)
processed_ds['freeboard'].load().values.shape: (2100, 53973)  # Expected: (2100, 53973)
processed_ds['cell_mask'].values.shape: (465044,)  # Expected: (465044,)
evaluated full_to_masked shape: 53973  # Expected: (53973,)
evaluated masked_to_full shape: 53973  # Expected: (53973,)
processed_ds['num_raw_files'].item(): 2100  # Expected: 2100
Number of cells considered for patching: 53973
Cluster sizes:
min size 256
max size 256
smallest count (np.int64(209), 256)
max count (np.int64(0), 256)
number of patches: 210
LAST PATCH SIZE:  256
Contains a -1 index  False
Elapsed time for MonthlyOrDailyNetCDFDataset __init__: 2.204026710242033 seconds
========== SPLITTING THE DATASET ===================
Training data length:    1939
Validation data length:  55
Testing data length:     55
Total Time Steps =  2049
Number of training batches 121
Number of validation batches 3
Number of test batches after drop_last incomplete batch 3
===== Printing Dataset ===== 
<Monthly_fd_nF_data.zarr
Instance of MonthlyOrDailyNetCDFDataset
2083 viable time steps (only includes up to the last possible input date)
53973 cells/time_step
2100 files loaded 
2100 ice_area length
2100 freeboard length
Patchify Algorithm: row_by_row
 # The following should be (2100, 53973) for Monthly data at a latitude_threshold of 40
(2100, 53973) shape of ice_area
(2100, 53973) shape of freeboard
210 indices_per_patch_id # Should be 210>
===== Sample at dataset[0] ===== 
Fetched start index 0: Time=1850-01-01T00:30:00.000000000
Fetched end   index 12: Time=1851-01-01T00:30:00.000000000
Fetched target start index 12: Time=1851-01-01T00:30:00.000000000
Fetched target end   index 18: Time=1851-07-01T00:30:00.000000000
Year is 1850
Month is 1
Day is 1
===== Start and End Dates for Each Set =====
Training set start date: 1850-01-01T00:30:00.000000000
Training set end date (cosmetic): 2012-12-01T00:30:00.000000000
(actual last viable target day): 2012-12-01T00:30:00.000000000
Validation set start date: 2013-01-01T00:30:00.000000000
Validation set end date (cosmetic): 2018-12-01T00:30:00.000000000
(actual last viable target day): 2018-12-01T00:30:00.000000000
Testing set start date: 2019-01-01T00:30:00.000000000
Testing set end date (cosmetic): 2024-12-01T00:30:00.000000000
(actual last viable target day): 2024-12-01T00:30:00.000000000
===== Starting DataLoader ====
train_loader length: 121
val_loader length: 3
test_loader length: 3
input_tensor should be of shape (context_length, num_patches, num_features, patch_size)
actual input_tensor.shape = torch.Size([12, 210, 2, 256])
target_tensor should be of shape (forecast_horizon, num_patches, patch_size)
actual target_tensor.shape = torch.Size([6, 210, 256])
SKIPPED TRAINING
SKIPPED SAVING THE MODEL
peCOM_results/peCOM_Mfd_nF_D128_B16_lt40_P210_L256_T12_Fh6_e40_ROW_model.pth
Calling IceForecastTransformer __init__
Elapsed time: 0.02 seconds
End of IceForecastTransformer __init__
Model loaded successfully!
Job finished at Wed 15 Oct 2025 12:22:55 AM PDT
Renamed job to: PECOM_h6_rows
Patchify strategy: rows
Forecast horizon: 6
Xarray version 2025.6.1
Zarr version 2.18.3
Numpy version 2.2.6
PyTorch version 2.5.1
Total nCells:        465044
Mask size:           53973
cells_per_patch:     256
n_patches:           210
Model Version: peCOM_Mfd_nF_D128_B16_lt40_P210_L256_T12_Fh6_e40_ROW
Dataset Name: Monthly_fd_nF_data.zarr
System Version: 3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:45:41) [GCC 13.3.0]
Pandas version 2.3.1
Matplotlib version 3.10.5
Seaborn version 0.13.2
Number of GPUs: 4
Processor Name: x86_64
Physical Cores: 64
Logical Cores: 128
Current CPU Frequency: 2635.92 MHz
Min CPU Frequency: 1500.00 MHz
Max CPU Frequency: 2450.00 MHz
Total CPU Usage: 0.5%
===== Making the Dataset Class: TRIAL_RUN MODE IS False ===== 
<xarray.Dataset> Size: 922MB
Dimensions:         (nCells_full: 465044, time: 2100, nCells_masked: 53973)
Coordinates:
  * nCells_full     (nCells_full) int64 4MB 0 1 2 3 ... 465041 465042 465043
  * nCells_masked   (nCells_masked) int64 432kB 0 1 2 3 ... 53970 53971 53972
  * time            (time) datetime64[ns] 17kB 1850-01-01T00:30:00 ... 2024-1...
Data variables:
    cell_mask       (nCells_full) bool 465kB dask.array<chunksize=(232522,), meta=np.ndarray>
    freeboard       (time, nCells_masked) float32 453MB dask.array<chunksize=(132, 3374), meta=np.ndarray>
    full_to_masked  <U1337572 5MB ...
    ice_area        (time, nCells_masked) float32 453MB dask.array<chunksize=(132, 3374), meta=np.ndarray>
    masked_to_full  <U1337572 5MB ...
    num_raw_files   int64 8B ...
    times           (time) datetime64[ns] 17kB dask.array<chunksize=(2100,), meta=np.ndarray>
processed_ds['times'].values.shape: (2100,)  # Expected: (2100,)
Type of self.times: <class 'numpy.ndarray'>
Data type of elements in self.times: datetime64[ns]
1850-01-01T00:30:00.000000000
processed_ds['ice_area'].load().values.shape: (2100, 53973)  # Expected: (2100, 53973)
processed_ds['freeboard'].load().values.shape: (2100, 53973)  # Expected: (2100, 53973)
processed_ds['cell_mask'].values.shape: (465044,)  # Expected: (465044,)
evaluated full_to_masked shape: 53973  # Expected: (53973,)
evaluated masked_to_full shape: 53973  # Expected: (53973,)
processed_ds['num_raw_files'].item(): 2100  # Expected: 2100
Number of cells considered for patching: 53973
Cluster sizes:
min size 256
max size 256
smallest count (np.int64(209), 256)
max count (np.int64(0), 256)
number of patches: 210
LAST PATCH SIZE:  256
Contains a -1 index  False
Elapsed time for MonthlyOrDailyNetCDFDataset __init__: 2.1703569451346993 seconds
========== SPLITTING THE DATASET ===================
Training data length:    1939
Validation data length:  55
Testing data length:     55
Total Time Steps =  2049
Number of training batches 121
Number of validation batches 3
Number of test batches after drop_last incomplete batch 3
===== Printing Dataset ===== 
<Monthly_fd_nF_data.zarr
Instance of MonthlyOrDailyNetCDFDataset
2083 viable time steps (only includes up to the last possible input date)
53973 cells/time_step
2100 files loaded 
2100 ice_area length
2100 freeboard length
Patchify Algorithm: row_by_row
 # The following should be (2100, 53973) for Monthly data at a latitude_threshold of 40
(2100, 53973) shape of ice_area
(2100, 53973) shape of freeboard
210 indices_per_patch_id # Should be 210>
===== Sample at dataset[0] ===== 
Fetched start index 0: Time=1850-01-01T00:30:00.000000000
Fetched end   index 12: Time=1851-01-01T00:30:00.000000000
Fetched target start index 12: Time=1851-01-01T00:30:00.000000000
Fetched target end   index 18: Time=1851-07-01T00:30:00.000000000
Year is 1850
Month is 1
Day is 1
===== Start and End Dates for Each Set =====
Training set start date: 1850-01-01T00:30:00.000000000
Training set end date (cosmetic): 2012-12-01T00:30:00.000000000
(actual last viable target day): 2012-12-01T00:30:00.000000000
Validation set start date: 2013-01-01T00:30:00.000000000
Validation set end date (cosmetic): 2018-12-01T00:30:00.000000000
(actual last viable target day): 2018-12-01T00:30:00.000000000
Testing set start date: 2019-01-01T00:30:00.000000000
Testing set end date (cosmetic): 2024-12-01T00:30:00.000000000
(actual last viable target day): 2024-12-01T00:30:00.000000000
===== Starting DataLoader ====
train_loader length: 121
val_loader length: 3
test_loader length: 3
input_tensor should be of shape (context_length, num_patches, num_features, patch_size)
actual input_tensor.shape = torch.Size([12, 210, 2, 256])
target_tensor should be of shape (forecast_horizon, num_patches, patch_size)
actual target_tensor.shape = torch.Size([6, 210, 256])
SKIPPED TRAINING
SKIPPED SAVING THE MODEL
peCOM_results/peCOM_Mfd_nF_D128_B16_lt40_P210_L256_T12_Fh6_e40_ROW_model.pth
Calling IceForecastTransformer __init__
Elapsed time: 0.02 seconds
End of IceForecastTransformer __init__
Model loaded successfully!
Processing batch 1/3
Job finished at Wed 15 Oct 2025 01:24:20 AM PDT
Renamed job to: PECOM_h6_rows
Patchify strategy: rows
Forecast horizon: 6
Xarray version 2025.6.1
Zarr version 2.18.3
Numpy version 2.2.6
PyTorch version 2.5.1
Total nCells:        465044
Mask size:           53973
cells_per_patch:     256
n_patches:           210
Model Version: peCOM_Mfd_nF_D128_B16_lt40_P210_L256_T12_Fh6_e40_ROW
Dataset Name: Monthly_fd_nF_data.zarr
System Version: 3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:45:41) [GCC 13.3.0]
Pandas version 2.3.1
Matplotlib version 3.10.5
Seaborn version 0.13.2
Number of GPUs: 4
Processor Name: x86_64
Physical Cores: 64
Logical Cores: 128
Current CPU Frequency: 2630.69 MHz
Min CPU Frequency: 1500.00 MHz
Max CPU Frequency: 2450.00 MHz
Total CPU Usage: 0.3%
===== Making the Dataset Class: TRIAL_RUN MODE IS False ===== 
<xarray.Dataset> Size: 922MB
Dimensions:         (nCells_full: 465044, time: 2100, nCells_masked: 53973)
Coordinates:
  * nCells_full     (nCells_full) int64 4MB 0 1 2 3 ... 465041 465042 465043
  * nCells_masked   (nCells_masked) int64 432kB 0 1 2 3 ... 53970 53971 53972
  * time            (time) datetime64[ns] 17kB 1850-01-01T00:30:00 ... 2024-1...
Data variables:
    cell_mask       (nCells_full) bool 465kB dask.array<chunksize=(232522,), meta=np.ndarray>
    freeboard       (time, nCells_masked) float32 453MB dask.array<chunksize=(132, 3374), meta=np.ndarray>
    full_to_masked  <U1337572 5MB ...
    ice_area        (time, nCells_masked) float32 453MB dask.array<chunksize=(132, 3374), meta=np.ndarray>
    masked_to_full  <U1337572 5MB ...
    num_raw_files   int64 8B ...
    times           (time) datetime64[ns] 17kB dask.array<chunksize=(2100,), meta=np.ndarray>
processed_ds['times'].values.shape: (2100,)  # Expected: (2100,)
Type of self.times: <class 'numpy.ndarray'>
Data type of elements in self.times: datetime64[ns]
1850-01-01T00:30:00.000000000
processed_ds['ice_area'].load().values.shape: (2100, 53973)  # Expected: (2100, 53973)
processed_ds['freeboard'].load().values.shape: (2100, 53973)  # Expected: (2100, 53973)
processed_ds['cell_mask'].values.shape: (465044,)  # Expected: (465044,)
evaluated full_to_masked shape: 53973  # Expected: (53973,)
evaluated masked_to_full shape: 53973  # Expected: (53973,)
processed_ds['num_raw_files'].item(): 2100  # Expected: 2100
Number of cells considered for patching: 53973
Cluster sizes:
min size 256
max size 256
smallest count (np.int64(209), 256)
max count (np.int64(0), 256)
number of patches: 210
LAST PATCH SIZE:  256
Contains a -1 index  False
Elapsed time for MonthlyOrDailyNetCDFDataset __init__: 2.3972532991319895 seconds
========== SPLITTING THE DATASET ===================
Training data length:    1939
Validation data length:  55
Testing data length:     55
Total Time Steps =  2049
Number of training batches 121
Number of validation batches 3
Number of test batches after drop_last incomplete batch 3
===== Printing Dataset ===== 
<Monthly_fd_nF_data.zarr
Instance of MonthlyOrDailyNetCDFDataset
2083 viable time steps (only includes up to the last possible input date)
53973 cells/time_step
2100 files loaded 
2100 ice_area length
2100 freeboard length
Patchify Algorithm: row_by_row
 # The following should be (2100, 53973) for Monthly data at a latitude_threshold of 40
(2100, 53973) shape of ice_area
(2100, 53973) shape of freeboard
210 indices_per_patch_id # Should be 210>
===== Sample at dataset[0] ===== 
Fetched start index 0: Time=1850-01-01T00:30:00.000000000
Fetched end   index 12: Time=1851-01-01T00:30:00.000000000
Fetched target start index 12: Time=1851-01-01T00:30:00.000000000
Fetched target end   index 18: Time=1851-07-01T00:30:00.000000000
Year is 1850
Month is 1
Day is 1
===== Start and End Dates for Each Set =====
Training set start date: 1850-01-01T00:30:00.000000000
Training set end date (cosmetic): 2012-12-01T00:30:00.000000000
(actual last viable target day): 2012-12-01T00:30:00.000000000
Validation set start date: 2013-01-01T00:30:00.000000000
Validation set end date (cosmetic): 2018-12-01T00:30:00.000000000
(actual last viable target day): 2018-12-01T00:30:00.000000000
Testing set start date: 2019-01-01T00:30:00.000000000
Testing set end date (cosmetic): 2024-12-01T00:30:00.000000000
(actual last viable target day): 2024-12-01T00:30:00.000000000
===== Starting DataLoader ====
train_loader length: 121
val_loader length: 3
test_loader length: 3
input_tensor should be of shape (context_length, num_patches, num_features, patch_size)
actual input_tensor.shape = torch.Size([12, 210, 2, 256])
target_tensor should be of shape (forecast_horizon, num_patches, patch_size)
actual target_tensor.shape = torch.Size([6, 210, 256])
SKIPPED TRAINING
SKIPPED SAVING THE MODEL
peCOM_results/peCOM_Mfd_nF_D128_B16_lt40_P210_L256_T12_Fh6_e40_ROW_model.pth
Calling IceForecastTransformer __init__
Elapsed time: 0.02 seconds
End of IceForecastTransformer __init__
Model loaded successfully!
Processing batch 1/3
Processing batch 2/3
Processing batch 3/3
Monthly RMSE plot saved as peCOM_Mfd_nF_D128_B16_lt40_P210_L256_T12_Fh6_e40_ROW_monthly_RMSE.png

--- Calculating Temporal Degradation Metrics ---
Plot saved: peCOM_Mfd_nF_D128_B16_lt40_P210_L256_T12_Fh6_e40_ROW_SIC_temporal_degradation.png
Elapsed time for full evaluation: 7.7870446727611125 seconds
Monthly and step RMSE degradation heatmap saved.

==================================================
       TOP 30 WORST RMSE DATES AND FORECAST STEPS
==================================================
RMSE       Date            Forecast Step  
----------------------------------------
0.2650   2020-09         3              
0.2618   2020-10         3              
0.2611   2022-10         3              
0.2581   2020-09         2              
0.2483   2022-12         4              
0.2450   2021-09         2              
0.2433   2021-09         3              
0.2429   2020-11         3              
0.2405   2020-11         4              
0.2402   2022-09         2              
0.2376   2019-12         4              
0.2370   2022-09         3              
0.2344   2020-09         4              
0.2297   2020-12         4              
0.2281   2022-10         2              
0.2279   2021-12         4              
0.2269   2021-10         3              
0.2269   2020-10         4              
0.2265   2022-11         3              
0.2255   2019-09         3              
0.2235   2023-01         4              
0.2226   2020-08         2              
0.2219   2020-08         3              
0.2216   2020-10         2              
0.2209   2019-09         2              
0.2204   2023-02         5              
0.2203   2019-10         3              
0.2190   2022-11         4              
0.2171   2020-08         4              
0.2169   2022-12         3              
==================================================

--- Calculating Overall Distribution Metrics (JSD) ---

Jensen-Shannon Distance between Actual vs. Predicted SIC for ROW patchify  (Overall Distribution): 0.2881
Actual vs. Predicted SIC histogram saved as peCOM_Mfd_nF_D128_B16_lt40_P210_L256_T12_Fh6_e40_ROW_SIC_xy_Overall.png
Job finished at Wed 15 Oct 2025 02:23:57 AM PDT
