Renamed job to: PECOM_h12_latlon_spillover
Patchify strategy: latlon_spillover
Forecast horizon: 12
Xarray version 2025.6.1
Zarr version 2.18.3
Numpy version 2.2.6
PyTorch version 2.5.1
Total nCells:        465044
Mask size:           53973
cells_per_patch:     256
n_patches:           210
Model Version: peCOM_Mfd_nF_D128_B16_lt40_P210_L256_T12_Fh12_e40_LLSO
Dataset Name: Monthly_fd_nF_data.zarr
System Version: 3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:45:41) [GCC 13.3.0]
Pandas version 2.3.1
Matplotlib version 3.10.5
Seaborn version 0.13.2
Number of GPUs: 4
Processor Name: x86_64
Physical Cores: 64
Logical Cores: 128
Current CPU Frequency: 2450.59 MHz
Min CPU Frequency: 1500.00 MHz
Max CPU Frequency: 2450.00 MHz
Total CPU Usage: 0.1%
===== Making the Dataset Class: TRIAL_RUN MODE IS False ===== 
<xarray.Dataset> Size: 922MB
Dimensions:         (nCells_full: 465044, time: 2100, nCells_masked: 53973)
Coordinates:
  * nCells_full     (nCells_full) int64 4MB 0 1 2 3 ... 465041 465042 465043
  * nCells_masked   (nCells_masked) int64 432kB 0 1 2 3 ... 53970 53971 53972
  * time            (time) datetime64[ns] 17kB 1850-01-01T00:30:00 ... 2024-1...
Data variables:
    cell_mask       (nCells_full) bool 465kB dask.array<chunksize=(232522,), meta=np.ndarray>
    freeboard       (time, nCells_masked) float32 453MB dask.array<chunksize=(132, 3374), meta=np.ndarray>
    full_to_masked  <U1337572 5MB ...
    ice_area        (time, nCells_masked) float32 453MB dask.array<chunksize=(132, 3374), meta=np.ndarray>
    masked_to_full  <U1337572 5MB ...
    num_raw_files   int64 8B ...
    times           (time) datetime64[ns] 17kB dask.array<chunksize=(2100,), meta=np.ndarray>
processed_ds['times'].values.shape: (2100,)  # Expected: (2100,)
Type of self.times: <class 'numpy.ndarray'>
Data type of elements in self.times: datetime64[ns]
1850-01-01T00:30:00.000000000
processed_ds['ice_area'].load().values.shape: (2100, 53973)  # Expected: (2100, 53973)
processed_ds['freeboard'].load().values.shape: (2100, 53973)  # Expected: (2100, 53973)
processed_ds['cell_mask'].values.shape: (465044,)  # Expected: (465044,)
evaluated full_to_masked shape: 53973  # Expected: (53973,)
evaluated masked_to_full shape: 53973  # Expected: (53973,)
processed_ds['num_raw_files'].item(): 2100  # Expected: 2100
LAST PATCH SIZE:  256
Contains a -1 index  False
Cluster sizes:
min size 256
max size 256
smallest count (np.int64(0), 256)
max count (np.int64(205), 256)
number of patches: 210
Elapsed time for MonthlyOrDailyNetCDFDataset __init__: 2.3917705230414867 seconds
========== SPLITTING THE DATASET ===================
Training data length:    1933
Validation data length:  49
Testing data length:     49
Total Time Steps =  2031
Number of training batches 120
Number of validation batches 3
Number of test batches after drop_last incomplete batch 3
===== Printing Dataset ===== 
<Monthly_fd_nF_data.zarr
Instance of MonthlyOrDailyNetCDFDataset
2077 viable time steps (only includes up to the last possible input date)
53973 cells/time_step
2100 files loaded 
2100 ice_area length
2100 freeboard length
Patchify Algorithm: latlon_spillover
 # The following should be (2100, 53973) for Monthly data at a latitude_threshold of 40
(2100, 53973) shape of ice_area
(2100, 53973) shape of freeboard
210 indices_per_patch_id # Should be 210>
===== Sample at dataset[0] ===== 
Fetched start index 0: Time=1850-01-01T00:30:00.000000000
Fetched end   index 12: Time=1851-01-01T00:30:00.000000000
Fetched target start index 12: Time=1851-01-01T00:30:00.000000000
Fetched target end   index 24: Time=1852-01-01T00:30:00.000000000
Year is 1850
Month is 1
Day is 1
===== Start and End Dates for Each Set =====
Training set start date: 1850-01-01T00:30:00.000000000
Training set end date (cosmetic): 2012-12-01T00:30:00.000000000
(actual last viable target day): 2012-12-01T00:30:00.000000000
Validation set start date: 2013-01-01T00:30:00.000000000
Validation set end date (cosmetic): 2018-12-01T00:30:00.000000000
(actual last viable target day): 2018-12-01T00:30:00.000000000
Testing set start date: 2019-01-01T00:30:00.000000000
Testing set end date (cosmetic): 2024-12-01T00:30:00.000000000
(actual last viable target day): 2024-12-01T00:30:00.000000000
===== Starting DataLoader ====
train_loader length: 120
val_loader length: 3
test_loader length: 3
input_tensor should be of shape (context_length, num_patches, num_features, patch_size)
actual input_tensor.shape = torch.Size([12, 210, 2, 256])
target_tensor should be of shape (forecast_horizon, num_patches, patch_size)
actual target_tensor.shape = torch.Size([12, 210, 256])
SKIPPED TRAINING
SKIPPED SAVING THE MODEL
peCOM_results/peCOM_Mfd_nF_D128_B16_lt40_P210_L256_T12_Fh12_e40_LLSO_model.pth
Calling IceForecastTransformer __init__
Elapsed time: 0.02 seconds
End of IceForecastTransformer __init__
Model loaded successfully!
Processing batch 1/3
Job finished at Wed 15 Oct 2025 01:19:27 AM PDT
Renamed job to: PECOM_h12_latlon_spillover
Patchify strategy: latlon_spillover
Forecast horizon: 12
Xarray version 2025.6.1
Zarr version 2.18.3
Numpy version 2.2.6
PyTorch version 2.5.1
Total nCells:        465044
Mask size:           53973
cells_per_patch:     256
n_patches:           210
Model Version: peCOM_Mfd_nF_D128_B16_lt40_P210_L256_T12_Fh12_e40_LLSO
Dataset Name: Monthly_fd_nF_data.zarr
System Version: 3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:45:41) [GCC 13.3.0]
Pandas version 2.3.1
Matplotlib version 3.10.5
Seaborn version 0.13.2
Number of GPUs: 4
Processor Name: x86_64
Physical Cores: 64
Logical Cores: 128
Current CPU Frequency: 2458.20 MHz
Min CPU Frequency: 1500.00 MHz
Max CPU Frequency: 2450.00 MHz
Total CPU Usage: 0.3%
===== Making the Dataset Class: TRIAL_RUN MODE IS False ===== 
<xarray.Dataset> Size: 922MB
Dimensions:         (nCells_full: 465044, time: 2100, nCells_masked: 53973)
Coordinates:
  * nCells_full     (nCells_full) int64 4MB 0 1 2 3 ... 465041 465042 465043
  * nCells_masked   (nCells_masked) int64 432kB 0 1 2 3 ... 53970 53971 53972
  * time            (time) datetime64[ns] 17kB 1850-01-01T00:30:00 ... 2024-1...
Data variables:
    cell_mask       (nCells_full) bool 465kB dask.array<chunksize=(232522,), meta=np.ndarray>
    freeboard       (time, nCells_masked) float32 453MB dask.array<chunksize=(132, 3374), meta=np.ndarray>
    full_to_masked  <U1337572 5MB ...
    ice_area        (time, nCells_masked) float32 453MB dask.array<chunksize=(132, 3374), meta=np.ndarray>
    masked_to_full  <U1337572 5MB ...
    num_raw_files   int64 8B ...
    times           (time) datetime64[ns] 17kB dask.array<chunksize=(2100,), meta=np.ndarray>
processed_ds['times'].values.shape: (2100,)  # Expected: (2100,)
Type of self.times: <class 'numpy.ndarray'>
Data type of elements in self.times: datetime64[ns]
1850-01-01T00:30:00.000000000
processed_ds['ice_area'].load().values.shape: (2100, 53973)  # Expected: (2100, 53973)
processed_ds['freeboard'].load().values.shape: (2100, 53973)  # Expected: (2100, 53973)
processed_ds['cell_mask'].values.shape: (465044,)  # Expected: (465044,)
evaluated full_to_masked shape: 53973  # Expected: (53973,)
evaluated masked_to_full shape: 53973  # Expected: (53973,)
processed_ds['num_raw_files'].item(): 2100  # Expected: 2100
LAST PATCH SIZE:  256
Contains a -1 index  False
Cluster sizes:
min size 256
max size 256
smallest count (np.int64(0), 256)
max count (np.int64(205), 256)
number of patches: 210
Elapsed time for MonthlyOrDailyNetCDFDataset __init__: 2.3822624441236258 seconds
========== SPLITTING THE DATASET ===================
Training data length:    1933
Validation data length:  49
Testing data length:     49
Total Time Steps =  2031
Number of training batches 120
Number of validation batches 3
Number of test batches after drop_last incomplete batch 3
===== Printing Dataset ===== 
<Monthly_fd_nF_data.zarr
Instance of MonthlyOrDailyNetCDFDataset
2077 viable time steps (only includes up to the last possible input date)
53973 cells/time_step
2100 files loaded 
2100 ice_area length
2100 freeboard length
Patchify Algorithm: latlon_spillover
 # The following should be (2100, 53973) for Monthly data at a latitude_threshold of 40
(2100, 53973) shape of ice_area
(2100, 53973) shape of freeboard
210 indices_per_patch_id # Should be 210>
===== Sample at dataset[0] ===== 
Fetched start index 0: Time=1850-01-01T00:30:00.000000000
Fetched end   index 12: Time=1851-01-01T00:30:00.000000000
Fetched target start index 12: Time=1851-01-01T00:30:00.000000000
Fetched target end   index 24: Time=1852-01-01T00:30:00.000000000
Year is 1850
Month is 1
Day is 1
===== Start and End Dates for Each Set =====
Training set start date: 1850-01-01T00:30:00.000000000
Training set end date (cosmetic): 2012-12-01T00:30:00.000000000
(actual last viable target day): 2012-12-01T00:30:00.000000000
Validation set start date: 2013-01-01T00:30:00.000000000
Validation set end date (cosmetic): 2018-12-01T00:30:00.000000000
(actual last viable target day): 2018-12-01T00:30:00.000000000
Testing set start date: 2019-01-01T00:30:00.000000000
Testing set end date (cosmetic): 2024-12-01T00:30:00.000000000
(actual last viable target day): 2024-12-01T00:30:00.000000000
===== Starting DataLoader ====
train_loader length: 120
val_loader length: 3
test_loader length: 3
input_tensor should be of shape (context_length, num_patches, num_features, patch_size)
actual input_tensor.shape = torch.Size([12, 210, 2, 256])
target_tensor should be of shape (forecast_horizon, num_patches, patch_size)
actual target_tensor.shape = torch.Size([12, 210, 256])
SKIPPED TRAINING
SKIPPED SAVING THE MODEL
peCOM_results/peCOM_Mfd_nF_D128_B16_lt40_P210_L256_T12_Fh12_e40_LLSO_model.pth
Calling IceForecastTransformer __init__
Elapsed time: 0.05 seconds
End of IceForecastTransformer __init__
Model loaded successfully!
Processing batch 1/3
Processing batch 2/3
Processing batch 3/3
Monthly RMSE plot saved as peCOM_Mfd_nF_D128_B16_lt40_P210_L256_T12_Fh12_e40_LLSO_monthly_RMSE.png

--- Calculating Temporal Degradation Metrics ---
Plot saved: peCOM_Mfd_nF_D128_B16_lt40_P210_L256_T12_Fh12_e40_LLSO_SIC_temporal_degradation.png
Elapsed time for full evaluation: 12.19348186487332 seconds
Monthly and step RMSE degradation heatmap saved.

==================================================
       TOP 30 WORST RMSE DATES AND FORECAST STEPS
==================================================
RMSE       Date            Forecast Step  
----------------------------------------
0.2563   2023-03         4              
0.2490   2022-03         4              
0.2453   2022-03         3              
0.2427   2021-03         4              
0.2421   2023-02         4              
0.2401   2022-02         4              
0.2396   2023-02         5              
0.2388   2023-02         3              
0.2387   2022-02         5              
0.2386   2021-03         3              
0.2378   2022-02         3              
0.2369   2023-04         5              
0.2356   2020-03         4              
0.2342   2023-03         5              
0.2324   2019-03         3              
0.2319   2022-03         5              
0.2311   2022-02         6              
0.2303   2022-02         2              
0.2299   2023-02         6              
0.2288   2020-03         3              
0.2279   2020-02         4              
0.2277   2020-02         5              
0.2276   2021-02         4              
0.2271   2022-04         4              
0.2262   2021-02         5              
0.2257   2021-02         3              
0.2251   2021-03         5              
0.2249   2020-02         3              
0.2248   2022-03         6              
0.2235   2023-03         6              
==================================================

--- Calculating Overall Distribution Metrics (JSD) ---

Jensen-Shannon Distance between Actual vs. Predicted SIC for LLSO patchify  (Overall Distribution): 0.3524
Actual vs. Predicted SIC histogram saved as peCOM_Mfd_nF_D128_B16_lt40_P210_L256_T12_Fh12_e40_LLSO_SIC_xy_Overall.png
Job finished at Wed 15 Oct 2025 02:37:47 AM PDT
